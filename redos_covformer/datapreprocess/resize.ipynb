{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T11:03:09.186315Z",
     "start_time": "2024-09-03T11:03:08.966295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "\n",
    "def resize_nc_variables(nc_file, new_shape=(60, 80)):\n",
    "    dataset = xr.open_dataset(nc_file)\n",
    "    resized_data = {}\n",
    "\n",
    "    for var_name in dataset.variables:\n",
    "        data = dataset[var_name].values\n",
    "        data[data == -32768.0] = np.nan  # 替换标记值为 NaN\n",
    "\n",
    "        if data.ndim == 3:  # 三维数据\n",
    "            depth, lat, lon = dataset[var_name].dims\n",
    "            if var_name in ['u', 'v']:\n",
    "                if var_name == 'u':\n",
    "                    lat, lon = 'latu', 'lonu'\n",
    "                elif var_name == 'v':\n",
    "                    lat, lon = 'latv', 'lonv'\n",
    "            old_coords = (dataset[depth].values, dataset[lat].values, dataset[lon].values)\n",
    "            new_coords = np.meshgrid(dataset[depth].values,\n",
    "                                     np.linspace(dataset[lat].values.min(), dataset[lat].values.max(), new_shape[0]),\n",
    "                                     np.linspace(dataset[lon].values.min(), dataset[lon].values.max(), new_shape[1]),\n",
    "                                     indexing='ij')\n",
    "            interpolator = RegularGridInterpolator(old_coords, data, bounds_error=False, fill_value=np.nan)\n",
    "            resized_data[var_name] = interpolator(tuple(map(np.ravel, new_coords))).reshape(len(dataset[depth]), *new_shape)\n",
    "\n",
    "        elif data.ndim == 2:  # 二维数据\n",
    "            lat, lon = dataset[var_name].dims\n",
    "            old_coords = (dataset[lat].values, dataset[lon].values)\n",
    "            new_coords = np.meshgrid(np.linspace(dataset[lat].values.min(), dataset[lat].values.max(), new_shape[0]),\n",
    "                                     np.linspace(dataset[lon].values.min(), dataset[lon].values.max(), new_shape[1]),\n",
    "                                     indexing='ij')\n",
    "            interpolator = RegularGridInterpolator(old_coords, data, bounds_error=False, fill_value=np.nan)\n",
    "            resized_data[var_name] = interpolator(tuple(map(np.ravel, new_coords))).reshape(new_shape)\n",
    "        \n",
    "    return resized_data\n",
    "\n",
    "# 示例调用\n",
    "file_path=\"E:/Dataset/redos/Subset_1.0_1995/subset_19950214.nc\"\n",
    "resized_data = resize_nc_variables(file_path)\n",
    "\n",
    "# 验证每个变量的形状\n",
    "for var_name, data in resized_data.items():\n",
    "    print(f\"{var_name} 的插值后形状: {data.shape}\")\n",
    "    num_samples=5\n",
    "    print(f\"{var_name} 的前 {num_samples} 个数据:\\n{resized_data[var_name].flat[:num_samples]}\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def count_valid_and_nan(data):\n",
    "    \"\"\"\n",
    "    统计数据中的有效值和NaN值的数量。\n",
    "    \n",
    "    参数:\n",
    "        data (np.ndarray): 需要统计的数据。\n",
    "        \n",
    "    返回:\n",
    "        valid_count (int): 有效值的数量。\n",
    "        nan_count (int): NaN值的数量。\n",
    "    \"\"\"\n",
    "    valid_count = np.sum(~np.isnan(data))\n",
    "    nan_count = np.sum(np.isnan(data))\n",
    "    return valid_count, nan_count\n",
    "\n",
    "# 示例数据加载和统计\n",
    "# 假设 data 是你的数据字典，包含 'u' 和 'v' 变量\n",
    "\n",
    "# 统计 'u' 数据\n",
    "u_valid, u_nan = count_valid_and_nan(resized_data['u'])\n",
    "print(f\"u 数据中的有效值数量: {u_valid}\")\n",
    "print(f\"u 数据中的NaN值数量: {u_nan}\")\n",
    "\n",
    "# 统计 'v' 数据\n",
    "v_valid, v_nan = count_valid_and_nan(resized_data['v'])\n",
    "print(f\"v 数据中的有效值数量: {v_valid}\")\n",
    "print(f\"v 数据中的NaN值数量: {v_nan}\")\n"
   ],
   "id": "e6177a31747dd0b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t 的插值后形状: (24, 60, 80)\n",
      "t 的前 5 个数据:\n",
      "[4.94823551 4.92691479 4.92760798 4.95510073 4.95374738]\n",
      "s 的插值后形状: (24, 60, 80)\n",
      "s 的前 5 个数据:\n",
      "[34.58226013 34.57994278 34.57947458 34.58125754 34.58079041]\n",
      "zeta 的插值后形状: (60, 80)\n",
      "zeta 的前 5 个数据:\n",
      "[0.75479156 0.74220871 0.72920666 0.71569428 0.70158887]\n",
      "u 的插值后形状: (24, 60, 80)\n",
      "u 的前 5 个数据:\n",
      "[nan nan nan nan nan]\n",
      "v 的插值后形状: (24, 60, 80)\n",
      "v 的前 5 个数据:\n",
      "[nan nan nan nan nan]\n",
      "u 数据中的有效值数量: 48975\n",
      "u 数据中的NaN值数量: 66225\n",
      "v 数据中的有效值数量: 49628\n",
      "v 数据中的NaN值数量: 65572\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path=\"E:/Dataset/redos/Subset_1.0_1995/subset_19950214.nc\"\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.ndimage import zoom\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "\n",
    "def interpolate_3d_data(nc_file, var_name, target_shape=(60, 80), anomaly_value=-32768.0):\n",
    "    \"\"\"\n",
    "    插值三维数据并忽略异常值。\n",
    "\n",
    "    参数:\n",
    "    - nc_file (str): NetCDF 文件路径。\n",
    "    - var_name (str): 需要插值的变量名称。\n",
    "    - target_shape (tuple): 目标纬度和经度的形状 (height, width)。\n",
    "    - anomaly_value (float): 异常值的标记，默认值为 -32768.0。\n",
    "\n",
    "    返回:\n",
    "    - new_data (numpy.ndarray): 插值后的数据。\n",
    "    \"\"\"\n",
    "    # 打开NetCDF文件并读取变量数据\n",
    "    dataset = xr.open_dataset(nc_file)\n",
    "    data = dataset[var_name].values\n",
    "\n",
    "    # 将标记值替换为 NaN\n",
    "    data[data == anomaly_value] = np.nan\n",
    "\n",
    "    # 获取原始数据的深度、纬度和经度\n",
    "    depth = dataset['depth'].values\n",
    "    lat = dataset['lat'].values\n",
    "    lon = dataset['lon'].values\n",
    "\n",
    "    # 构建新的网格\n",
    "    new_lat = np.linspace(lat.min(), lat.max(), target_shape[0])\n",
    "    new_lon = np.linspace(lon.min(), lon.max(), target_shape[1])\n",
    "\n",
    "    # 进行插值，忽略 NaN 值\n",
    "    interpolator = RegularGridInterpolator((depth, lat, lon), data, bounds_error=False, fill_value=np.nan)\n",
    "    new_data = interpolator(np.meshgrid(depth, new_lat, new_lon, indexing='ij'))\n",
    "\n",
    "    # 插值完成后，进一步处理 NaN 值，例如填充或删除\n",
    "    # new_data = np.nan_to_num(new_data)  # 将所有 NaN 填充为 0\n",
    "\n",
    "    return new_data\n",
    "\n",
    "# 示例调用\n",
    "nc_file = 'your_nc_file.nc'\n",
    "var_name = 's'\n",
    "interpolated_data = interpolate_3d_data(nc_file, var_name)\n",
    "print(interpolated_data.shape)\n",
    "# 示例调用\n",
    "nc_file = \"/path/to/your/ncfile.nc\"\n",
    "# new_data_dict = interpolate_nc_data(nc_file)\n",
    "\n",
    "def load_all_nc_data(path, start_year, end_year):\n",
    "    data_dict = {}\n",
    "    data_dict_Jan={}\n",
    "    current_date = datetime(start_year, 1, 1)\n",
    "    end_date = datetime(end_year + 1, 1, 1)\n",
    "    while current_date < end_date:\n",
    "        date_str = current_date.strftime('%Y%m%d')\n",
    "        nc_file = path + '/subset_' + date_str + '.nc'\n",
    "        # 当月份大于2时停止循环\n",
    "        if current_date.month > 3:\n",
    "            print(\"月份大于3，停止循环。\")\n",
    "            break\n",
    "        # 读取 NetCDF 文件\n",
    "        dataset = xr.open_dataset(nc_file)\n",
    "        target_shape = (60, 80)\n",
    "\n",
    "        # 计算缩放因子\n",
    "        zoom_factors = (target_shape[0] / img.shape[0], target_shape[1] / img.shape[1])\n",
    "        \n",
    "        # 使用双线性插值进行调整\n",
    "        resized_img = zoom(img, zoom_factors, order=1)  # order=1表示双线性插值\n",
    "\n",
    "        print(resized_img.shape)  # 输出应该是(60, 80)\n",
    "        for var_name in dataset.variables:\n",
    "            data = dataset[var_name].values\n",
    "            data[data == -32768.0] = np.nan  # 替换标记值\n",
    "            if current_date.month == 1:\n",
    "                if var_name not in data_dict_Jan:\n",
    "                    data_dict_Jan[var_name] = []  # 初始化为列表\n",
    "                # 处理1月份的数据\n",
    "                data_dict_Jan[var_name].append(data)\n",
    "            else:\n",
    "                if var_name not in data_dict:\n",
    "                    data_dict[var_name] = []  # 初始化为列表\n",
    "                # 处理其他月份的数据\n",
    "                data_dict[var_name].append(data)\n",
    "\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "        # 将列表转换为数组\n",
    "    for var_name in data_dict:\n",
    "        data_dict[var_name] = np.array(data_dict[var_name])\n",
    "        data_dict_Jan[var_name] = np.array(data_dict_Jan[var_name])\n",
    "    return data_dict, data_dict_Jan\n",
    "file_path=\"E:/Dataset/redos/Subset_1.0_1995\"\n",
    "# 假设原始数据为img，形状为(28, 52)\n",
    "img = np.random.rand(28, 52)  # 示例数据\n",
    "\n",
    "# 目标尺寸\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c90ae17251c6e8cc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

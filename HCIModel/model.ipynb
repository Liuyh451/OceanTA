{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-03T03:21:30.058092Z",
     "start_time": "2024-10-03T03:21:30.024785Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class BasicUnit(nn.Module):\n",
    "    \"\"\"\n",
    "        提取长短期特征\n",
    "        输入通道数：32\n",
    "        输出通道数：32\n",
    "        参数：\n",
    "        input_channels, output_channels, data\n",
    "        返回：\n",
    "        特征图 Tensor (N*C*L)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super(BasicUnit, self).__init__()\n",
    "        # 使用3x1的卷积核\n",
    "        self.conv1 = nn.Conv1d(input_channels, output_channels, kernel_size=3,padding=1)  # 第一组卷积\n",
    "        self.conv2 = nn.Conv1d(input_channels, output_channels, kernel_size=3,padding=1)  # 第二组卷积\n",
    "        self.conv3 = nn.Conv1d(input_channels, output_channels, kernel_size=3,padding=1)  # 第三组卷积\n",
    "        self.conv4 = nn.Conv1d(input_channels, output_channels, kernel_size=3,padding=1)  # 第四组卷积\n",
    "\n",
    "    def forward(self, x):\n",
    "        A = torch.tanh(self.conv1(x))  # A = tanh(x * w1 + b1)\n",
    "        B = torch.sigmoid(self.conv2(x))  # B = σ(x * w2 + b2)\n",
    "        C = torch.tanh(self.conv3(x))  # C = tanh(x * w3 + b3)\n",
    "        D = torch.sigmoid(self.conv4(x))  # D = σ(x * w4 + b4)\n",
    "\n",
    "        E = A * B + C * D  # E = A ⊗ B + C ⊗ D\n",
    "        return E\n",
    "\n",
    "\n",
    "class BrainAnalysisModule(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels,time_step):\n",
    "        super(BrainAnalysisModule, self).__init__()\n",
    "        self.fc_input_channels=output_channels*time_step\n",
    "        self.fc_output_channels=1\n",
    "        self.basic_unit1 = BasicUnit(input_channels, output_channels)  # 第一个基本单元\n",
    "        self.basic_unit2 = BasicUnit(output_channels, output_channels)  # 第二个基本单元\n",
    "        self.fc = nn.Linear(self.fc_input_channels, self.fc_output_channels)  # 添加全连接层\n",
    "        # self.fc = nn.Conv1d(output_channels, 8, kernel_size=1)  # 1x1卷积层替代全连接层\n",
    "\n",
    "    def forward(self, x):\n",
    "        output1 = self.basic_unit1(x)  # 经过第一个基本单元\n",
    "        print(\"output1\", output1.shape)\n",
    "        output2 = self.basic_unit2(output1)  # 以output1作为第二个单元的输入\n",
    "        print(\"output2\", output2.shape)\n",
    "        output2_flat = output2.view(output2.size(0), -1)  # 将输出展平成2D形状，适用于全连接层\n",
    "        print(\"output2_flat\", output2_flat.shape)\n",
    "        final_output = self.fc(output2_flat)  # 经过全连接层\n",
    "        # final_output = self.fc(output2)  # 经过全连接层\n",
    "        return final_output\n",
    "\n",
    "# 示例使用\n",
    "if __name__ == \"__main__\":\n",
    "    # 假设输入数据形状为 (批大小, 通道数, 序列长度)\n",
    "    input_data = torch.randn(40, 32, 17)  # 批大小为 40，通道数为 32，序列长度为 3000\n",
    "    brain_module = BrainAnalysisModule(input_channels=32, output_channels=32,time_step=17)  # 创建模块实例\n",
    "    output = brain_module(input_data)  # 前向传播\n",
    "    print(output.shape)  # 打印输出形状\n",
    "    print(output[0])\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output1 torch.Size([40, 32, 17])\n",
      "output2 torch.Size([40, 32, 17])\n",
      "output2_flat torch.Size([40, 544])\n",
      "torch.Size([40, 1])\n",
      "tensor([-0.0422], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T15:34:14.573054Z",
     "start_time": "2024-09-29T15:34:14.560317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AnticipationModule:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, predicted_modes):\n",
    "        \"\"\"\n",
    "        计算重建预测值\n",
    "        输入通道数：8\n",
    "        输出通道数：1\n",
    "        参数：\n",
    "        predicted_modes: List[torch.Tensor] - 各个分解模式的预测值\n",
    "        返回：\n",
    "        torch.Tensor - 重建预测值\n",
    "        \"\"\"\n",
    "        # 将所有模式的预测值求和\n",
    "        reconstructed_prediction = sum(predicted_modes)\n",
    "        return reconstructed_prediction\n",
    "\n",
    "# 示例：使用 AnticipationModule\n",
    "# if __name__ == \"__main__\":\n",
    "#     # 假设有8个模式的预测值\n",
    "#     predicted_modes = [torch.rand(1) for _ in range(8)]  # 生成随机预测值作为示例\n",
    "# \n",
    "#     anticipation_module = AnticipationModule()\n",
    "#     reconstructed_prediction = anticipation_module.forward(predicted_modes)\n",
    "# \n",
    "#     print(\"重建预测值：\", reconstructed_prediction.item())\n",
    "#     print(\"预测值的维度：\", reconstructed_prediction.size())  # 或者使用 reconstructed_prediction.shape"
   ],
   "id": "2f83ab61b503c16f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "重建预测值： 3.883603096008301\n",
      "预测值的维度： torch.Size([1])\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "class ModelTrainer:\n",
    "    def __init__(self, train_data, val_data, test_data, input_channels, output_channels, \n",
    "                 batch_size=40, num_epochs=200, initial_lr=0.01, min_lr=0.00001):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.test_data = test_data\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.initial_lr = initial_lr\n",
    "        self.min_lr = min_lr\n",
    "\n",
    "        # 初始化模型\n",
    "        self.brain_analysis_module = BrainAnalysisModule(input_channels, output_channels).to(self.device)\n",
    "        self.anticipation_module = AnticipationModule().to(self.device)\n",
    "\n",
    "        # 定义损失函数和优化器\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(list(self.brain_analysis_module.parameters()) + \n",
    "                                     list(self.anticipation_module.parameters()), \n",
    "                                     lr=self.initial_lr, weight_decay=0.01)\n",
    "    def save_model(self, path):\n",
    "        # torch.save({'net': self.network.state_dict(),\n",
    "        #             'optimizer': self.opt.optimizer.state_dict()}, path)\n",
    "    def train(self):\n",
    "        print('loading train dataloader')\n",
    "        train_loader = DataLoader(self.train_data, batch_size=self.batch_size, shuffle=True)\n",
    "        print('loading eval dataloader')\n",
    "        val_loader = DataLoader(self.val_data, batch_size=self.batch_size, shuffle=False)\n",
    "        learning_rate = self.initial_lr\n",
    "        decay_steps = self.num_epochs // 10\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            print('\\nepoch: {0}'.format(epoch + 1))\n",
    "            # 训练模式\n",
    "            self.brain_analysis_module.train()\n",
    "            self.anticipation_module.train()\n",
    "            for inputs, targets in train_loader:\n",
    "                inputs = inputs.to(self.device)  # 获取输入数据并转移到 GPU\n",
    "                targets = targets.to(self.device)  # 获取目标数据并转移到 GPU\n",
    "\n",
    "                # 前向传播\n",
    "                y_hat = self.brain_analysis_module(inputs)\n",
    "                final_output = self.anticipation_module(y_hat)\n",
    "\n",
    "                # 计算损失\n",
    "                loss = self.criterion(final_output, targets)  # 使用 targets 计算损失\n",
    "\n",
    "                # 反向传播和优化\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            # 学习率衰减\n",
    "            if epoch % decay_steps == 0 and learning_rate > self.min_lr:\n",
    "                learning_rate *= 0.5\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr'] = learning_rate\n",
    "\n",
    "            # 验证模式\n",
    "            self.validate(val_loader)\n",
    "\n",
    "            # 打印损失\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f'Epoch [{epoch + 1}/{self.num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    def validate(self, val_loader):\n",
    "        self.brain_analysis_module.eval()\n",
    "        self.anticipation_module.eval()\n",
    "        val_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs in val_loader:\n",
    "                inputs = inputs[0].to(self.device)\n",
    "                y_hat = self.brain_analysis_module(inputs)\n",
    "                final_output = self.anticipation_module(y_hat)\n",
    "                loss = self.criterion(final_output, inputs)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        print(f'Validation Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "# 假设已经准备好的数据集\n",
    "train_data = TensorDataset(train_tensor)  # 训练集的 TensorDataset\n",
    "val_data = TensorDataset(val_tensor)      # 验证集的 TensorDataset\n",
    "test_data = TensorDataset(test_tensor)    # 测试集的 TensorDataset\n",
    "\n",
    "# 创建模型训练器实例\n",
    "trainer = ModelTrainer(train_data=train_data, \n",
    "                       val_data=val_data, \n",
    "                       test_data=test_data, \n",
    "                       input_channels=input_channels, \n",
    "                       output_channels=output_channels, \n",
    "                       batch_size=40, \n",
    "                       num_epochs=200, \n",
    "                       initial_lr=0.01, \n",
    "                       min_lr=0.00001)\n",
    "\n",
    "# 训练模型\n",
    "trainer.train()\n"
   ],
   "id": "a94418b1286e8e80"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

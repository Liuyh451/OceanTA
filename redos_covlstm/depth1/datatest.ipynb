{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-14T05:24:52.713881Z",
     "start_time": "2024-08-14T05:24:52.703880Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import netCDF4 as nc\n"
   ],
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:24:52.839891Z",
     "start_time": "2024-08-14T05:24:52.827891Z"
    }
   },
   "cell_type": "code",
   "source": "import xarray as xr",
   "id": "37b3833bda647501",
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:24:52.934896Z",
     "start_time": "2024-08-14T05:24:52.926896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def increment_number(number_str):\n",
    "    # 自增数字部分\n",
    "    new_number = str(int(number_str) + 1).zfill(2)  # 保持两位数格式\n",
    "    return new_number\n",
    "num1='1'\n",
    "def extract_nc_layer_data(path,type,depth):\n",
    "    number_str = \"00\"\n",
    "    daily_data = []\n",
    "    #使用31天的数据\n",
    "    for i in range(31):\n",
    "        number_str = increment_number(number_str)\n",
    "        num=number_str\n",
    "        nc_file=path+'/subset_file_'+num+'.nc'\n",
    "        file_obj = nc.Dataset(nc_file)\n",
    "        #zeta为海表没有深度，所以永远为0\n",
    "        if type=='zeta':\n",
    "            temp_lv0 = file_obj.variables[type][ :, :]\n",
    "        else:\n",
    "            temp_lv0 = file_obj.variables[type][depth, :, :]\n",
    "        daily_data.append(temp_lv0)\n",
    "    day_lon_lat = np.array(daily_data)\n",
    "    return day_lon_lat"
   ],
   "id": "f396e8acb93c75fa",
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:24:52.981899Z",
     "start_time": "2024-08-14T05:24:52.962899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_dataset(data, time_step):\n",
    "    dataX = []\n",
    "    for i in range(data.shape[0] - time_step + 1):\n",
    "        dataX.append(data[i:i + time_step])\n",
    "    return np.array(dataX)"
   ],
   "id": "b81fa10d5f578690",
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:24:53.013903Z",
     "start_time": "2024-08-14T05:24:53.001902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_raw_data(vtype, depth, time_step,nc_file):\n",
    "    #训练用的数据是第0层，也就是海表，原来那个是按照深度进行划分的，这个nc文件是按天数进行划分的，这里只有一天，所以shape[0]=1\n",
    "    train_argo = extract_nc_layer_data(nc_file,vtype,0)\n",
    "    data_mask=train_argo\n",
    "    label_argo = extract_nc_layer_data(nc_file,vtype,depth)\n",
    "    width = train_argo.shape[2] #对应经度\n",
    "    lenth = train_argo.shape[1] #对应纬度\n",
    "    X = create_dataset(train_argo, time_step)\n",
    "    X = X.reshape(X.shape[0],time_step,lenth,width,1)\n",
    "    Y = label_argo[time_step-1 : label_argo.shape[0]] \n",
    "    Y =Y.reshape(Y.shape[0],lenth,width,1)\n",
    "    #X 转置维度，变为 (样本数, 时间步长, 通道数, 纬度, 经度)。\n",
    "    #Y 转置维度，变为 (样本数, 时间步长， 经度, 纬度)。\n",
    "    X = X.transpose(0,1,4,2,3)\n",
    "    Y = Y.transpose(0,3,1,2)\n",
    "    return X, Y,data_mask"
   ],
   "id": "f2879410f524d19f",
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:24:54.824352Z",
     "start_time": "2024-08-14T05:24:53.033904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#这几个数据格式一样，但是内容不一样，读的分别是不同的列\n",
    "import netCDF4 as nc\n",
    "file_path = 'E:/DataSet/redos/REDOS_1.0_1994/1'\n",
    "train_sssa,_,_=read_raw_data('s',0,3,file_path)\n",
    "train_ssha,_,_ = read_raw_data('zeta',0,3,file_path) #海面高度异常（Sea Level Anomaly）,他写的是sla，但是这里是zeta\n",
    "train_sswu,_,_ = read_raw_data('u',0,3,file_path)#U vwnd分量的风速（即沿经度方向的风速）,这里是u\n",
    "train_sswv,_,_ = read_raw_data('v',0,3,file_path)#V vwnd分量的风速（即沿纬度方向的风速），这里是v\n",
    "train_argo, label_argo,data_mask_t = read_raw_data('t', 1, 3,file_path)#temp 代表温度数据,预测深度为1时的海温"
   ],
   "id": "46d748e23247a1ec",
   "outputs": [],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:24:54.840357Z",
     "start_time": "2024-08-14T05:24:54.829355Z"
    }
   },
   "cell_type": "code",
   "source": "train_sswv.shape,train_sswu.shape,train_sssa.shape,train_argo.shape,train_ssha.shape,label_argo.shape",
   "id": "ab42e2adf54dfb06",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29, 3, 1, 28, 52),\n",
       " (29, 3, 1, 28, 52),\n",
       " (29, 3, 1, 28, 52),\n",
       " (29, 3, 1, 28, 52),\n",
       " (29, 3, 1, 28, 52),\n",
       " (29, 1, 28, 52))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:24:54.856355Z",
     "start_time": "2024-08-14T05:24:54.844355Z"
    }
   },
   "cell_type": "code",
   "source": "label_argo.shape,train_argo.shape\n",
   "id": "40fd7f973d210458",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29, 1, 28, 52), (29, 3, 1, 28, 52))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:24:54.872355Z",
     "start_time": "2024-08-14T05:24:54.859354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scaler(data):\n",
    "    #normalise [0,1]\n",
    "    data_max = np.nanmax(data)\n",
    "    data_min = np.nanmin(data)\n",
    "    data_scale = data_max - data_min\n",
    "    data_std = (data - data_min) / data_scale\n",
    "    # data_std = data_std * (2)  -1\n",
    "    data_std [np.isnan(data_std)] = 0\n",
    "    return data_std,data_min,data_scale\n",
    "\n",
    "#反归一化\n",
    "def unscaler(data, data_min, data_scale):\n",
    "    data_inv = (data * data_scale) + data_min\n",
    "    return data_inv"
   ],
   "id": "982481e7d6a7a5e4",
   "outputs": [],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:24:54.904356Z",
     "start_time": "2024-08-14T05:24:54.878356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#对数据进行归一化\n",
    "sta_train,_,_ = scaler(train_argo[:-12,:])\n",
    "ssa_train,_,_  = scaler(train_sssa[:-12,:])\n",
    "ssha_train,_,_ = scaler(train_ssha[:-12,:])\n",
    "sswu_train,_,_ = scaler(train_sswu[:-12,:])\n",
    "sswv_train,_,_ = scaler(train_sswv[:-12,:])\n",
    "true_train,_,_ = scaler(label_argo[:-12,:])"
   ],
   "id": "e0d14250205e86e3",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:24:54.934361Z",
     "start_time": "2024-08-14T05:24:54.912361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#用倒数12个数据作为验证集\n",
    "sta_test,_,_ = scaler(train_argo[-12:])\n",
    "ssa_test,_,_  = scaler(train_sssa[-12:])\n",
    "ssha_test,_,_ = scaler(train_ssha[-12:])\n",
    "sswu_test,_,_ = scaler(train_sswu[-12:])\n",
    "sswv_test,_,_ = scaler(train_sswv[-12:])"
   ],
   "id": "179355ca045252ba",
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:24:54.950360Z",
     "start_time": "2024-08-14T05:24:54.938362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def data_reduced(data,tag):\n",
    "    #全减\n",
    "    if tag==0:\n",
    "        data_new=data[:, :, :, :-1, :-1]\n",
    "    #第4维减1\n",
    "    elif tag==1:\n",
    "        data_new=data[:, :, :, :-1, :]\n",
    "    else:\n",
    "        data_new=data[:, :, :, :, :-1]\n",
    "    return data_new"
   ],
   "id": "44e734c1c8f79d52",
   "outputs": [],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:24:54.966362Z",
     "start_time": "2024-08-14T05:24:54.954362Z"
    }
   },
   "cell_type": "code",
   "source": "sta_test.shape,ssa_test.shape,ssha_test.shape,sswu_test.shape,sswv_test.shape,label_argo.shape",
   "id": "11bdc4fdb816244b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12, 3, 1, 28, 52),\n",
       " (12, 3, 1, 28, 52),\n",
       " (12, 3, 1, 28, 52),\n",
       " (12, 3, 1, 28, 52),\n",
       " (12, 3, 1, 28, 52),\n",
       " (29, 1, 28, 52))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:24:54.982362Z",
     "start_time": "2024-08-14T05:24:54.968362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#将多个不同类型的训练数据和测试数据沿着指定轴进行拼接，axis=2即增加特征的数量（即通道或变量的数量）\n",
    "sta_train = np.concatenate((sta_train,ssa_train,ssha_train,sswu_train,sswv_train),axis = 2 )\n",
    "sta_test = np.concatenate((sta_test,ssa_test,ssha_test,sswu_test,sswv_test),axis = 2)"
   ],
   "id": "637aaabe12ea4b19",
   "outputs": [],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:24:54.998363Z",
     "start_time": "2024-08-14T05:24:54.984364Z"
    }
   },
   "cell_type": "code",
   "source": "true_train.shape",
   "id": "ed2ef039110e3d21",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 1, 28, 52)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:24:55.013365Z",
     "start_time": "2024-08-14T05:24:55.001366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "true_test,test_min,test_scale = scaler(label_argo[-12:])\n",
    "#true_test是归一化后的 label_argo 数据，对应于最后 12 个时间步的标签数据\n",
    "#test_min是 label_argo[-12:] 数据中的最小值，在归一化过程中用作偏移量。\n",
    "#test_scale是 label_argo[-12:] 数据的范围，即最大值与最小值的差值。在归一化过程中用于缩放数据"
   ],
   "id": "6570683b81737540",
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:24:55.045368Z",
     "start_time": "2024-08-14T05:24:55.016365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#将拼接后的数据作为训练集\n",
    "X_train = sta_train\n",
    "#训练集的标签\n",
    "true_train = true_train\n",
    "\n",
    "#训练集上用于评估\n",
    "X_eval = sta_test\n",
    "#\n",
    "true_eval = true_test\n",
    "X_test = sta_test\n",
    "true_test = true_test\n",
    "true_test.shape,X_eval.shape"
   ],
   "id": "b77d32c0d5755c87",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12, 1, 28, 52), (12, 3, 5, 28, 52))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:24:55.061368Z",
     "start_time": "2024-08-14T05:24:55.048368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "from torch.utils.data import Dataset"
   ],
   "id": "6a7cfe733af2e182",
   "outputs": [],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:24:55.093370Z",
     "start_time": "2024-08-14T05:24:55.068369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Configs:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "configs = Configs()\n",
    "\n",
    "# trainer related\n",
    "configs.vtype = 't'\n",
    "# configs.depth = 11\n",
    "# configs.time_step = 1\n",
    "configs.n_cpu = 0\n",
    "# configs.device = torch.device('cpu')\n",
    "configs.device = torch.device('cuda:0')\n",
    "configs.batch_size_test = 4\n",
    "configs.batch_size = 2\n",
    "#configs.lr = 0.001\n",
    "configs.weight_decay = 0\n",
    "configs.display_interval = 10\n",
    "configs.num_epochs = 50\n",
    "#这是早停的耐心参数。即使模型在900个epoch内没有改善性能，训练仍会继续。如果在900个epoch内性能没有改善，训练将停止\n",
    "configs.early_stopping = True\n",
    "configs.patience = 50\n",
    "#禁用梯度裁剪（Gradient Clipping）。梯度裁剪用于防止梯度爆炸问题，但在这里未启用\n",
    "configs.gradient_clipping = False\n",
    "#设置梯度裁剪的阈值为1。如果梯度裁剪启用，梯度的最大值将被限制为1。不过在这种配置下，由于梯度裁剪被禁用，这个参数实际上不会生效\n",
    "configs.clipping_threshold = 1.\n",
    "\n",
    "# lr warmup\n",
    "#这是学习率预热的步数设置。在训练的前3000步内，学习率将逐渐从一个较小的值线性增加到预设的学习率。这种技术通常用于训练的初始阶段，以帮助模型更稳定地开始训练，减少初期的震荡。\n",
    "configs.warmup = 150\n",
    "\n",
    "# data related\n",
    "#这是输入数据的维度设置。这通常取决于你使用的数据的特征数或通道数\n",
    "configs.input_dim = 1 # 4 #这里应该是5吧 但是写的1我总感觉是5\n",
    "'''\n",
    "人家这个1是对的这个模型就是要保证输入通道和输出通道得一样\n",
    "默认为1\n",
    "'''\n",
    "configs.output_dim = 1\n",
    "#表示模型的输入序列长度为5，即模型在预测时会使用前5个时间步的数据作为输入\n",
    "configs.input_length = 5\n",
    "#表示模型的输出长度为1，即模型预测一个时间步的值。通常用于单步预测\n",
    "configs.output_length = 1\n",
    "#表示输入序列中的数据点之间的时间间隔为1。即数据是逐步连续的，没有跳跃\n",
    "configs.input_gap = 1\n",
    "#表示预测的时间偏移量为24。这可能意味着模型的目标是预测未来24个时间步后的数据点\n",
    "configs.pred_shift = 24\n",
    "#这个列表包含了一系列的深度值，这可能与模型的层次结构或者不同深度的输入特征相关联\n",
    "configs.depth = [5,6,11,16,20,25,30,34,36,38,40,42,44,46,48,50,51,52,53,54,55,57]\n",
    "#这个列表可能对应于不同深度的索引或层次级别。每个索引可能用于定位或选择特定深度的特征或数据\n",
    "configs.depthindex = [30,50, 100, 150, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900]\n",
    "\n",
    "# model\n",
    "#表示模型的维度即每个输入数据在模型中的表示为256维\n",
    "configs.d_model = 256\n",
    "#表示模型处理数据时的patch（小块）的大小为5×5。这通常用于图像或序列数据的分块处理\n",
    "configs.patch_size = (5,5)\n",
    "#表示嵌入的空间尺寸。这里12*16可能是表示最终嵌入的特征图的尺寸（例如视觉模型中的特征图大小）\n",
    "configs.emb_spatial_size = 12*16\n",
    "#表示多头注意力机制中的头数为4。多头注意力允许模型从不同的角度“看”数据，从而捕捉不同的关系\n",
    "configs.nheads = 4\n",
    "#表示前馈神经网络的维度用于增加模型的表达能力\n",
    "configs.dim_feedforward =512\n",
    "#表示在模型中使用的dropout率为0.3。Dropout是一种正则化技术，用于减少过拟合。\n",
    "configs.dropout = 0.3\n",
    "#表示编码器的层数为4。这意味着模型有4个堆叠的编码器层\n",
    "configs.num_encoder_layers = 4\n",
    "configs.num_decoder_layers = 4\n",
    "#这可能是学习率的衰减率（scheduler decay rate），用来控制模型训练过程中学习率的递减速度，以便在训练的后期进行更细致的优化\n",
    "configs.ssr_decay_rate = 3.e-6\n",
    "\n",
    "\n",
    "# plot 表示绘图的分辨率为600 DPI\n",
    "configs.plot_dpi = 600"
   ],
   "id": "237be25d7eb6364e",
   "outputs": [],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:24:55.109371Z",
     "start_time": "2024-08-14T05:24:55.096373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils import  cmip_dataset\n",
    "from utils import  Trainer"
   ],
   "id": "92ecc8ccc612c761",
   "outputs": [],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:24:55.125373Z",
     "start_time": "2024-08-14T05:24:55.112374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_train = cmip_dataset(X_train,true_train)\n",
    "print(dataset_train.GetDataShape())"
   ],
   "id": "1d9e727cf354fade",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sst input': (17, 3, 5, 28, 52), 'sst target': (17, 1, 28, 52)}\n"
     ]
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:24:55.140376Z",
     "start_time": "2024-08-14T05:24:55.127375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_eval = cmip_dataset(X_eval,true_eval)\n",
    "print(dataset_eval.GetDataShape())"
   ],
   "id": "3726ce816ba35504",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sst input': (12, 3, 5, 28, 52), 'sst target': (12, 1, 28, 52)}\n"
     ]
    }
   ],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:24:55.202045Z",
     "start_time": "2024-08-14T05:24:55.143376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = Trainer(configs)\n",
    "trainer.save_configs('config_train.pkl')\n"
   ],
   "id": "d557c5956dbda86f",
   "outputs": [],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:25:31.302364Z",
     "start_time": "2024-08-14T05:24:55.204046Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train(dataset_train, dataset_eval, 'checkpoint.chk')",
   "id": "49f2b703cde2b432",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 1\n",
      "batch training loss: 0.93740, ssr: 1.00000, lr: 0.00001\n",
      "epoch eval loss:\n",
      "sst: 1.02\n",
      "eval score is improved from inf to 1.01959, saving model\n",
      "\n",
      "epoch: 2\n",
      "batch training loss: 0.85274, ssr: 0.99997, lr: 0.00009\n",
      "epoch eval loss:\n",
      "sst: 1.00\n",
      "eval score is improved from 1.01959 to 1.00362, saving model\n",
      "\n",
      "epoch: 3\n",
      "batch training loss: 0.67516, ssr: 0.99994, lr: 0.00018\n",
      "epoch eval loss:\n",
      "sst: 0.92\n",
      "eval score is improved from 1.00362 to 0.92296, saving model\n",
      "\n",
      "epoch: 4\n",
      "batch training loss: 0.50174, ssr: 0.99992, lr: 0.00026\n",
      "epoch eval loss:\n",
      "sst: 0.67\n",
      "eval score is improved from 0.92296 to 0.66989, saving model\n",
      "\n",
      "epoch: 5\n",
      "batch training loss: 0.37738, ssr: 0.99989, lr: 0.00035\n",
      "epoch eval loss:\n",
      "sst: 0.40\n",
      "eval score is improved from 0.66989 to 0.39933, saving model\n",
      "\n",
      "epoch: 6\n",
      "batch training loss: 0.30103, ssr: 0.99986, lr: 0.00043\n",
      "epoch eval loss:\n",
      "sst: 0.28\n",
      "eval score is improved from 0.39933 to 0.27892, saving model\n",
      "\n",
      "epoch: 7\n",
      "batch training loss: 0.23439, ssr: 0.99984, lr: 0.00051\n",
      "epoch eval loss:\n",
      "sst: 0.21\n",
      "eval score is improved from 0.27892 to 0.21311, saving model\n",
      "\n",
      "epoch: 8\n",
      "batch training loss: 0.18532, ssr: 0.99981, lr: 0.00060\n",
      "epoch eval loss:\n",
      "sst: 0.17\n",
      "eval score is improved from 0.21311 to 0.17312, saving model\n",
      "\n",
      "epoch: 9\n",
      "batch training loss: 0.15582, ssr: 0.99978, lr: 0.00068\n",
      "epoch eval loss:\n",
      "sst: 0.15\n",
      "eval score is improved from 0.17312 to 0.14664, saving model\n",
      "\n",
      "epoch: 10\n",
      "batch training loss: 0.14045, ssr: 0.99975, lr: 0.00077\n",
      "epoch eval loss:\n",
      "sst: 0.13\n",
      "eval score is improved from 0.14664 to 0.13290, saving model\n",
      "\n",
      "epoch: 11\n",
      "batch training loss: 0.13245, ssr: 0.99973, lr: 0.00085\n",
      "epoch eval loss:\n",
      "sst: 0.13\n",
      "eval score is improved from 0.13290 to 0.12761, saving model\n",
      "\n",
      "epoch: 12\n",
      "batch training loss: 0.12811, ssr: 0.99970, lr: 0.00093\n",
      "epoch eval loss:\n",
      "sst: 0.13\n",
      "eval score is improved from 0.12761 to 0.12526, saving model\n",
      "\n",
      "epoch: 13\n",
      "batch training loss: 0.12545, ssr: 0.99967, lr: 0.00102\n",
      "epoch eval loss:\n",
      "sst: 0.12\n",
      "eval score is improved from 0.12526 to 0.12350, saving model\n",
      "\n",
      "epoch: 14\n",
      "batch training loss: 0.12360, ssr: 0.99965, lr: 0.00110\n",
      "epoch eval loss:\n",
      "sst: 0.12\n",
      "eval score is improved from 0.12350 to 0.12197, saving model\n",
      "\n",
      "epoch: 15\n",
      "batch training loss: 0.12212, ssr: 0.99962, lr: 0.00119\n",
      "epoch eval loss:\n",
      "sst: 0.12\n",
      "eval score is improved from 0.12197 to 0.12066, saving model\n",
      "\n",
      "epoch: 16\n",
      "batch training loss: 0.12077, ssr: 0.99959, lr: 0.00127\n",
      "epoch eval loss:\n",
      "sst: 0.12\n",
      "eval score is improved from 0.12066 to 0.11904, saving model\n",
      "\n",
      "epoch: 17\n",
      "batch training loss: 0.11903, ssr: 0.99957, lr: 0.00135\n",
      "epoch eval loss:\n",
      "sst: 0.12\n",
      "eval score is improved from 0.11904 to 0.11564, saving model\n",
      "\n",
      "epoch: 18\n",
      "batch training loss: 0.11540, ssr: 0.99954, lr: 0.00138\n",
      "epoch eval loss:\n",
      "sst: 0.09\n",
      "eval score is improved from 0.11564 to 0.09451, saving model\n",
      "\n",
      "epoch: 19\n",
      "batch training loss: 0.08999, ssr: 0.99951, lr: 0.00134\n",
      "epoch eval loss:\n",
      "sst: 0.05\n",
      "eval score is improved from 0.09451 to 0.05302, saving model\n",
      "\n",
      "epoch: 20\n",
      "batch training loss: 0.05899, ssr: 0.99948, lr: 0.00131\n",
      "epoch eval loss:\n",
      "sst: 0.04\n",
      "eval score is improved from 0.05302 to 0.04192, saving model\n",
      "\n",
      "epoch: 21\n",
      "batch training loss: 0.03790, ssr: 0.99946, lr: 0.00127\n",
      "epoch eval loss:\n",
      "sst: 0.03\n",
      "eval score is improved from 0.04192 to 0.03225, saving model\n",
      "\n",
      "epoch: 22\n",
      "batch training loss: 0.03079, ssr: 0.99943, lr: 0.00124\n",
      "epoch eval loss:\n",
      "sst: 0.02\n",
      "eval score is improved from 0.03225 to 0.02367, saving model\n",
      "\n",
      "epoch: 23\n",
      "batch training loss: 0.02387, ssr: 0.99940, lr: 0.00122\n",
      "epoch eval loss:\n",
      "sst: 0.02\n",
      "eval score is improved from 0.02367 to 0.02163, saving model\n",
      "\n",
      "epoch: 24\n",
      "batch training loss: 0.01992, ssr: 0.99938, lr: 0.00119\n",
      "epoch eval loss:\n",
      "sst: 0.02\n",
      "eval score is improved from 0.02163 to 0.01874, saving model\n",
      "\n",
      "epoch: 25\n",
      "batch training loss: 0.01730, ssr: 0.99935, lr: 0.00116\n",
      "epoch eval loss:\n",
      "sst: 0.02\n",
      "eval score is improved from 0.01874 to 0.01615, saving model\n",
      "\n",
      "epoch: 26\n",
      "batch training loss: 0.01563, ssr: 0.99932, lr: 0.00114\n",
      "epoch eval loss:\n",
      "sst: 0.01\n",
      "eval score is improved from 0.01615 to 0.01470, saving model\n",
      "\n",
      "epoch: 27\n",
      "batch training loss: 0.01430, ssr: 0.99930, lr: 0.00112\n",
      "epoch eval loss:\n",
      "sst: 0.01\n",
      "eval score is improved from 0.01470 to 0.01390, saving model\n",
      "\n",
      "epoch: 28\n",
      "batch training loss: 0.01331, ssr: 0.99927, lr: 0.00110\n",
      "epoch eval loss:\n",
      "sst: 0.01\n",
      "eval score is improved from 0.01390 to 0.01272, saving model\n",
      "\n",
      "epoch: 29\n",
      "batch training loss: 0.01255, ssr: 0.99924, lr: 0.00108\n",
      "epoch eval loss:\n",
      "sst: 0.01\n",
      "eval score is improved from 0.01272 to 0.01175, saving model\n",
      "\n",
      "epoch: 30\n",
      "batch training loss: 0.01180, ssr: 0.99921, lr: 0.00106\n",
      "epoch eval loss:\n",
      "sst: 0.01\n",
      "eval score is improved from 0.01175 to 0.01148, saving model\n",
      "\n",
      "epoch: 31\n",
      "batch training loss: 0.01113, ssr: 0.99919, lr: 0.00104\n",
      "epoch eval loss:\n",
      "sst: 0.01\n",
      "eval score is improved from 0.01148 to 0.01064, saving model\n",
      "\n",
      "epoch: 32\n",
      "batch training loss: 0.01066, ssr: 0.99916, lr: 0.00102\n",
      "epoch eval loss:\n",
      "sst: 0.01\n",
      "eval score is improved from 0.01064 to 0.01041, saving model\n",
      "\n",
      "epoch: 33\n",
      "batch training loss: 0.01027, ssr: 0.99913, lr: 0.00101\n",
      "epoch eval loss:\n",
      "sst: 0.01\n",
      "eval score is improved from 0.01041 to 0.00996, saving model\n",
      "\n",
      "epoch: 34\n",
      "batch training loss: 0.00989, ssr: 0.99911, lr: 0.00099\n",
      "epoch eval loss:\n",
      "sst: 0.01\n",
      "eval score is improved from 0.00996 to 0.00979, saving model\n",
      "\n",
      "epoch: 35\n",
      "batch training loss: 0.00968, ssr: 0.99908, lr: 0.00098\n",
      "epoch eval loss:\n",
      "sst: 0.01\n",
      "eval score is improved from 0.00979 to 0.00946, saving model\n",
      "\n",
      "epoch: 36\n",
      "batch training loss: 0.00956, ssr: 0.99905, lr: 0.00096\n",
      "epoch eval loss:\n",
      "sst: 0.01\n",
      "eval score is improved from 0.00946 to 0.00921, saving model\n",
      "\n",
      "epoch: 37\n",
      "batch training loss: 0.00914, ssr: 0.99903, lr: 0.00095\n",
      "epoch eval loss:\n",
      "sst: 0.01\n",
      "eval score is improved from 0.00921 to 0.00889, saving model\n",
      "\n",
      "epoch: 38\n",
      "batch training loss: 0.00884, ssr: 0.99900, lr: 0.00094\n",
      "epoch eval loss:\n",
      "sst: 0.01\n",
      "eval score is improved from 0.00889 to 0.00864, saving model\n",
      "\n",
      "epoch: 39\n",
      "batch training loss: 0.00867, ssr: 0.99897, lr: 0.00093\n",
      "epoch eval loss:\n",
      "sst: 0.01\n",
      "eval score is improved from 0.00864 to 0.00845, saving model\n",
      "\n",
      "epoch: 40\n",
      "batch training loss: 0.00846, ssr: 0.99894, lr: 0.00091\n",
      "epoch eval loss:\n",
      "sst: 0.01\n",
      "eval score is improved from 0.00845 to 0.00833, saving model\n",
      "\n",
      "epoch: 41\n",
      "batch training loss: 0.00835, ssr: 0.99892, lr: 0.00090\n",
      "epoch eval loss:\n",
      "sst: 0.01\n",
      "eval score is improved from 0.00833 to 0.00812, saving model\n",
      "\n",
      "epoch: 42\n",
      "batch training loss: 0.00815, ssr: 0.99889, lr: 0.00089\n",
      "epoch eval loss:\n",
      "sst: 0.01\n",
      "eval score is improved from 0.00812 to 0.00806, saving model\n",
      "\n",
      "epoch: 43\n",
      "batch training loss: 0.00802, ssr: 0.99886, lr: 0.00088\n",
      "epoch eval loss:\n",
      "sst: 0.01\n",
      "eval score is improved from 0.00806 to 0.00790, saving model\n",
      "\n",
      "epoch: 44\n",
      "batch training loss: 0.00790, ssr: 0.99884, lr: 0.00087\n",
      "epoch eval loss:\n",
      "sst: 0.01\n",
      "eval score is not improved for 1 epoch\n",
      "\n",
      "epoch: 45\n",
      "batch training loss: 0.00794, ssr: 0.99881, lr: 0.00086\n",
      "epoch eval loss:\n",
      "sst: 0.01\n",
      "eval score is improved from 0.00790 to 0.00764, saving model\n",
      "\n",
      "epoch: 46\n",
      "batch training loss: 0.00776, ssr: 0.99878, lr: 0.00085\n",
      "epoch eval loss:\n",
      "sst: 0.01\n",
      "eval score is improved from 0.00764 to 0.00757, saving model\n",
      "\n",
      "epoch: 47\n",
      "batch training loss: 0.00757, ssr: 0.99876, lr: 0.00084\n",
      "epoch eval loss:\n",
      "sst: 0.01\n",
      "eval score is improved from 0.00757 to 0.00751, saving model\n",
      "\n",
      "epoch: 48\n",
      "batch training loss: 0.00749, ssr: 0.99873, lr: 0.00083\n",
      "epoch eval loss:\n",
      "sst: 0.01\n",
      "eval score is improved from 0.00751 to 0.00741, saving model\n",
      "\n",
      "epoch: 49\n",
      "batch training loss: 0.00739, ssr: 0.99870, lr: 0.00082\n",
      "epoch eval loss:\n",
      "sst: 0.01\n",
      "eval score is improved from 0.00741 to 0.00729, saving model\n",
      "\n",
      "epoch: 50\n",
      "batch training loss: 0.00729, ssr: 0.99867, lr: 0.00082\n",
      "epoch eval loss:\n",
      "sst: 0.01\n",
      "eval score is improved from 0.00729 to 0.00723, saving model\n"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:25:31.318369Z",
     "start_time": "2024-08-14T05:25:31.305366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_test = cmip_dataset(X_test, true_test)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=configs.batch_size_test, shuffle=False)\n",
    "print(dataset_test.GetDataShape())"
   ],
   "id": "3c5f920d25cdcb0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sst input': (12, 3, 5, 28, 52), 'sst target': (12, 1, 28, 52)}\n"
     ]
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:25:31.412075Z",
     "start_time": "2024-08-14T05:25:31.321369Z"
    }
   },
   "cell_type": "code",
   "source": "chk = torch.load('./checkpoint.chk')",
   "id": "18d87c1ec9f278e7",
   "outputs": [],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:25:31.443078Z",
     "start_time": "2024-08-14T05:25:31.415074Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.network.load_state_dict(chk['net'])",
   "id": "c9903ca7b5ab7f08",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:25:31.569085Z",
     "start_time": "2024-08-14T05:25:31.446079Z"
    }
   },
   "cell_type": "code",
   "source": "loss_test, test_pred, test_true = trainer.infer_test(dataset=dataset_test, dataloader=dataloader_test)",
   "id": "6bd9daf8affc9069",
   "outputs": [],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:25:31.585088Z",
     "start_time": "2024-08-14T05:25:31.572087Z"
    }
   },
   "cell_type": "code",
   "source": "print(loss_test)",
   "id": "9bf1b18ea656957a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007229062728583813\n"
     ]
    }
   ],
   "execution_count": 122
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:25:31.679094Z",
     "start_time": "2024-08-14T05:25:31.588089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(test_true)\n",
    "print(test_pred)"
   ],
   "id": "c0622fd7844058bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[0.9805, 0.9916, 0.9918,  ..., 0.9900, 0.9894, 0.9756],\n",
      "          [0.9909, 0.9947, 0.9946,  ..., 0.9943, 0.9944, 0.9917],\n",
      "          [0.9903, 0.9945, 0.9943,  ..., 0.9939, 0.9939, 0.9917],\n",
      "          ...,\n",
      "          [0.9918, 0.9947, 0.9944,  ..., 0.9946, 0.9945, 0.9915],\n",
      "          [0.9919, 0.9945, 0.9945,  ..., 0.9946, 0.9945, 0.9917],\n",
      "          [0.9754, 0.9920, 0.9921,  ..., 0.9924, 0.9914, 0.9776]]],\n",
      "\n",
      "\n",
      "        [[[0.9805, 0.9916, 0.9918,  ..., 0.9900, 0.9894, 0.9756],\n",
      "          [0.9910, 0.9947, 0.9946,  ..., 0.9943, 0.9944, 0.9917],\n",
      "          [0.9903, 0.9945, 0.9943,  ..., 0.9939, 0.9939, 0.9916],\n",
      "          ...,\n",
      "          [0.9918, 0.9947, 0.9944,  ..., 0.9946, 0.9945, 0.9915],\n",
      "          [0.9919, 0.9945, 0.9945,  ..., 0.9946, 0.9945, 0.9917],\n",
      "          [0.9754, 0.9920, 0.9921,  ..., 0.9924, 0.9914, 0.9776]]],\n",
      "\n",
      "\n",
      "        [[[0.9805, 0.9916, 0.9918,  ..., 0.9900, 0.9894, 0.9757],\n",
      "          [0.9910, 0.9947, 0.9946,  ..., 0.9943, 0.9944, 0.9917],\n",
      "          [0.9903, 0.9945, 0.9943,  ..., 0.9939, 0.9939, 0.9917],\n",
      "          ...,\n",
      "          [0.9918, 0.9947, 0.9944,  ..., 0.9946, 0.9945, 0.9915],\n",
      "          [0.9919, 0.9945, 0.9945,  ..., 0.9946, 0.9945, 0.9917],\n",
      "          [0.9754, 0.9920, 0.9921,  ..., 0.9924, 0.9914, 0.9776]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.9802, 0.9915, 0.9918,  ..., 0.9901, 0.9894, 0.9757],\n",
      "          [0.9908, 0.9947, 0.9946,  ..., 0.9943, 0.9944, 0.9917],\n",
      "          [0.9901, 0.9944, 0.9943,  ..., 0.9939, 0.9939, 0.9916],\n",
      "          ...,\n",
      "          [0.9917, 0.9947, 0.9944,  ..., 0.9946, 0.9945, 0.9914],\n",
      "          [0.9919, 0.9945, 0.9945,  ..., 0.9945, 0.9945, 0.9915],\n",
      "          [0.9753, 0.9920, 0.9921,  ..., 0.9922, 0.9912, 0.9771]]],\n",
      "\n",
      "\n",
      "        [[[0.9801, 0.9915, 0.9918,  ..., 0.9901, 0.9894, 0.9756],\n",
      "          [0.9908, 0.9947, 0.9946,  ..., 0.9943, 0.9944, 0.9917],\n",
      "          [0.9901, 0.9944, 0.9943,  ..., 0.9939, 0.9939, 0.9916],\n",
      "          ...,\n",
      "          [0.9917, 0.9947, 0.9944,  ..., 0.9946, 0.9945, 0.9914],\n",
      "          [0.9919, 0.9945, 0.9945,  ..., 0.9945, 0.9945, 0.9915],\n",
      "          [0.9753, 0.9920, 0.9921,  ..., 0.9922, 0.9912, 0.9771]]],\n",
      "\n",
      "\n",
      "        [[[0.9800, 0.9915, 0.9918,  ..., 0.9901, 0.9894, 0.9757],\n",
      "          [0.9907, 0.9947, 0.9946,  ..., 0.9943, 0.9944, 0.9917],\n",
      "          [0.9900, 0.9944, 0.9943,  ..., 0.9939, 0.9939, 0.9916],\n",
      "          ...,\n",
      "          [0.9917, 0.9947, 0.9944,  ..., 0.9946, 0.9945, 0.9914],\n",
      "          [0.9919, 0.9945, 0.9945,  ..., 0.9945, 0.9944, 0.9915],\n",
      "          [0.9753, 0.9920, 0.9921,  ..., 0.9921, 0.9911, 0.9771]]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 123
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:25:31.694815Z",
     "start_time": "2024-08-14T05:25:31.681807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_pred = test_pred.cpu().numpy()\n",
    "test_true = test_true.cpu().numpy()"
   ],
   "id": "c664fcfd8036628a",
   "outputs": [],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:25:31.709809Z",
     "start_time": "2024-08-14T05:25:31.697809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_pred = unscaler(np.array(test_pred),test_min,test_scale)\n",
    "test_true = unscaler(np.array(test_true),test_min,test_scale)\n",
    "#todo 应该不用加，推测是用来加新数据的\n",
    "# test_pred = add('temp', 1, test_pred)\n",
    "# test_true = add('temp', 1, test_true)"
   ],
   "id": "8ed6a16b8ae7b817",
   "outputs": [],
   "execution_count": 125
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:25:31.724809Z",
     "start_time": "2024-08-14T05:25:31.713812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.save(\"./data/test_pred.npy\",test_pred)\n",
    "np.save(\"./data/test_true.npy\",test_true)"
   ],
   "id": "ae10727c039e20eb",
   "outputs": [],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:25:31.740811Z",
     "start_time": "2024-08-14T05:25:31.727812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(test_pred.shape)\n",
    "print(test_true.shape)\n",
    "#todo 这里他写的形状突然由(12, 1, 28, 52)变为了(12,28,52,1)没见到改变形状的操作啊\n",
    "#对数组重新塑形，这里是np不是张量\n",
    "test_true = np.transpose(test_true, (0, 3, 1, 2))\n",
    "test_pred = np.transpose(test_pred, (0, 3, 1, 2))\n",
    "print(test_pred.shape)\n",
    "print(test_true.shape)"
   ],
   "id": "a7b696ae13f77014",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 1, 28, 52)\n",
      "(12, 1, 28, 52)\n",
      "(12, 52, 1, 28)\n",
      "(12, 52, 1, 28)\n"
     ]
    }
   ],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:25:31.772814Z",
     "start_time": "2024-08-14T05:25:31.743815Z"
    }
   },
   "cell_type": "code",
   "source": "print(test_pred),print(test_true)",
   "id": "3c28185123c835a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-634.3672  -291.4297  -312.8164  ... -264.01953 -259.85352\n",
      "    -802.166  ]]\n",
      "\n",
      "  [[-271.26172 -168.52734 -176.24219 ... -169.26758 -173.47852\n",
      "    -255.59961]]\n",
      "\n",
      "  [[-264.39258 -170.88867 -181.45117 ... -177.58008 -176.55469\n",
      "    -253.67969]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-322.1875  -181.09766 -194.95703 ... -173.19922 -172.95703\n",
      "    -243.82617]]\n",
      "\n",
      "  [[-343.7207  -178.5586  -194.10938 ... -174.04102 -174.77734\n",
      "    -276.9004 ]]\n",
      "\n",
      "  [[-793.5     -266.94922 -267.92773 ... -274.42383 -267.56055\n",
      "    -727.90234]]]\n",
      "\n",
      "\n",
      " [[[-633.68164 -291.03516 -312.06836 ... -263.96484 -259.8086\n",
      "    -802.2422 ]]\n",
      "\n",
      "  [[-271.26172 -168.49023 -176.13281 ... -169.25195 -173.46875\n",
      "    -255.55469]]\n",
      "\n",
      "  [[-264.51953 -170.8711  -181.33594 ... -177.52344 -176.50781\n",
      "    -253.5918 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-322.47852 -181.17773 -195.23633 ... -173.17773 -173.07422\n",
      "    -244.2168 ]]\n",
      "\n",
      "  [[-343.1953  -178.5625  -194.41016 ... -174.13867 -174.85938\n",
      "    -277.22656]]\n",
      "\n",
      "  [[-794.05664 -267.33203 -268.94922 ... -274.8086  -267.8457\n",
      "    -728.6172 ]]]\n",
      "\n",
      "\n",
      " [[[-632.69727 -290.70898 -311.82617 ... -263.79883 -259.86328\n",
      "    -802.3262 ]]\n",
      "\n",
      "  [[-271.10547 -168.45898 -176.08789 ... -169.25586 -173.51562\n",
      "    -255.70703]]\n",
      "\n",
      "  [[-264.54883 -170.86719 -181.3125  ... -177.51562 -176.52148\n",
      "    -253.64844]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-321.6504  -181.04688 -195.04883 ... -173.18555 -173.26172\n",
      "    -244.89844]]\n",
      "\n",
      "  [[-342.6953  -178.47461 -194.24414 ... -174.18945 -175.02148\n",
      "    -277.9121 ]]\n",
      "\n",
      "  [[-792.39453 -266.9414  -268.33398 ... -274.81445 -267.9453\n",
      "    -728.7324 ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-643.1133  -295.49414 -318.8125  ... -265.12305 -260.44336\n",
      "    -803.916  ]]\n",
      "\n",
      "  [[-272.07422 -168.82617 -176.93555 ... -169.5332  -173.51367\n",
      "    -255.72852]]\n",
      "\n",
      "  [[-263.8125  -170.99805 -182.0586  ... -177.86914 -176.52539\n",
      "    -253.55664]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-319.3086  -180.91797 -195.57422 ... -173.1289  -174.78711\n",
      "    -250.58008]]\n",
      "\n",
      "  [[-341.76953 -178.44922 -195.61523 ... -174.54492 -176.39258\n",
      "    -283.86523]]\n",
      "\n",
      "  [[-791.4258  -267.02344 -270.21094 ... -276.35547 -272.02734\n",
      "    -744.23047]]]\n",
      "\n",
      "\n",
      " [[[-646.73047 -296.97266 -320.76172 ... -265.33398 -260.51758\n",
      "    -803.74414]]\n",
      "\n",
      "  [[-272.9004  -168.96875 -177.20703 ... -169.56836 -173.51562\n",
      "    -255.5957 ]]\n",
      "\n",
      "  [[-264.2539  -171.0957  -182.3086  ... -177.88867 -176.49414\n",
      "    -253.33789]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-319.29883 -180.93555 -195.54883 ... -173.17188 -174.9707\n",
      "    -251.36914]]\n",
      "\n",
      "  [[-342.61523 -178.55469 -195.82617 ... -174.6211  -176.53906\n",
      "    -284.51367]]\n",
      "\n",
      "  [[-794.0801  -267.48633 -270.60156 ... -276.4043  -272.2168\n",
      "    -744.416  ]]]\n",
      "\n",
      "\n",
      " [[[-648.541   -298.33594 -323.65625 ... -265.36328 -260.51562\n",
      "    -804.1953 ]]\n",
      "\n",
      "  [[-273.45312 -169.13281 -177.6543  ... -169.57812 -173.54688\n",
      "    -255.66602]]\n",
      "\n",
      "  [[-264.5625  -171.2461  -182.7832  ... -177.84961 -176.47266\n",
      "    -253.38477]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-318.88867 -180.90039 -195.44531 ... -173.16211 -175.11133\n",
      "    -252.03516]]\n",
      "\n",
      "  [[-341.78906 -178.4668  -195.52344 ... -174.71484 -176.72852\n",
      "    -285.38086]]\n",
      "\n",
      "  [[-791.50586 -266.75195 -269.50977 ... -276.60742 -272.64844\n",
      "    -745.69727]]]]\n",
      "[[[[4.7851562 4.8320312 4.7734375 ... 4.8554688 4.8789062 4.8398438]]\n",
      "\n",
      "  [[4.75      4.8164062 4.7734375 ... 4.8320312 4.8789062 4.875    ]]\n",
      "\n",
      "  [[4.7304688 4.7890625 4.7617188 ... 4.8359375 4.8710938 4.8984375]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[4.9296875 4.8867188 4.8242188 ... 4.7109375 4.7109375 4.6992188]]\n",
      "\n",
      "  [[4.9375    4.890625  4.8476562 ... 4.7304688 4.734375  4.71875  ]]\n",
      "\n",
      "  [[4.9414062 4.8945312 4.8671875 ... 4.75      4.75      4.734375 ]]]\n",
      "\n",
      "\n",
      " [[[4.8125    4.8359375 4.8046875 ... 4.8320312 4.875     4.84375  ]]\n",
      "\n",
      "  [[4.78125   4.8320312 4.7890625 ... 4.8203125 4.8632812 4.859375 ]]\n",
      "\n",
      "  [[4.7695312 4.8085938 4.7851562 ... 4.8203125 4.8515625 4.90625  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[4.921875  4.8671875 4.796875  ... 4.7070312 4.7148438 4.6953125]]\n",
      "\n",
      "  [[4.9257812 4.875     4.8125    ... 4.7265625 4.7382812 4.71875  ]]\n",
      "\n",
      "  [[4.9296875 4.8828125 4.8359375 ... 4.7382812 4.75      4.7382812]]]\n",
      "\n",
      "\n",
      " [[[4.8203125 4.8164062 4.8242188 ... 4.8320312 4.875     4.84375  ]]\n",
      "\n",
      "  [[4.8125    4.8085938 4.796875  ... 4.8164062 4.8632812 4.8867188]]\n",
      "\n",
      "  [[4.8085938 4.8046875 4.7773438 ... 4.828125  4.8515625 4.8789062]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[4.9101562 4.8632812 4.8164062 ... 4.7109375 4.71875   4.6992188]]\n",
      "\n",
      "  [[4.9296875 4.875     4.8398438 ... 4.734375  4.7460938 4.7226562]]\n",
      "\n",
      "  [[4.9453125 4.8984375 4.875     ... 4.7460938 4.7617188 4.7460938]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[4.859375  4.875     4.9023438 ... 4.8164062 4.859375  4.890625 ]]\n",
      "\n",
      "  [[4.8203125 4.859375  4.8945312 ... 4.8203125 4.8359375 4.8554688]]\n",
      "\n",
      "  [[4.7460938 4.8046875 4.8710938 ... 4.8203125 4.8125    4.859375 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[4.875     4.8632812 4.859375  ... 4.6914062 4.6953125 4.703125 ]]\n",
      "\n",
      "  [[4.9023438 4.890625  4.8828125 ... 4.703125  4.6992188 4.7070312]]\n",
      "\n",
      "  [[4.9335938 4.9140625 4.9101562 ... 4.7148438 4.703125  4.7070312]]]\n",
      "\n",
      "\n",
      " [[[4.8710938 4.90625   4.9375    ... 4.8164062 4.859375  4.8671875]]\n",
      "\n",
      "  [[4.8007812 4.84375   4.921875  ... 4.8046875 4.8359375 4.84375  ]]\n",
      "\n",
      "  [[4.6875    4.8164062 4.8710938 ... 4.8164062 4.8125    4.8554688]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[4.8984375 4.8867188 4.875     ... 4.6914062 4.6914062 4.6992188]]\n",
      "\n",
      "  [[4.921875  4.9101562 4.9023438 ... 4.7148438 4.703125  4.703125 ]]\n",
      "\n",
      "  [[4.9453125 4.9375    4.9335938 ... 4.7304688 4.7109375 4.7070312]]]\n",
      "\n",
      "\n",
      " [[[4.8789062 4.9140625 4.9648438 ... 4.8203125 4.84375   4.8671875]]\n",
      "\n",
      "  [[4.7460938 4.8710938 4.9257812 ... 4.8085938 4.828125  4.84375  ]]\n",
      "\n",
      "  [[4.7265625 4.8554688 4.84375   ... 4.8085938 4.8046875 4.8359375]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[4.875     4.875     4.875     ... 4.6992188 4.6875    4.6914062]]\n",
      "\n",
      "  [[4.9101562 4.90625   4.8984375 ... 4.7265625 4.7109375 4.6992188]]\n",
      "\n",
      "  [[4.9375    4.9335938 4.9257812 ... 4.75      4.7304688 4.7109375]]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:25:31.787815Z",
     "start_time": "2024-08-14T05:25:31.775816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_pred = np.squeeze(test_pred)\n",
    "test_true = np.squeeze(test_true)\n",
    "cha = (test_true[0] - test_pred[0]) ** 2\n",
    "test_pred[np.isnan(test_pred)] = 0\n",
    "test_true[np.isnan(test_true)] = 0"
   ],
   "id": "18040523012abb91",
   "outputs": [],
   "execution_count": 129
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:25:31.818816Z",
     "start_time": "2024-08-14T05:25:31.790818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rmse = []\n",
    "corr = []\n",
    "test_pred.shape[0]\n",
    "for i in range(test_pred.shape[0]):\n",
    "    predict_result = test_pred[i]\n",
    "    #print(predict_result)\n",
    "    true_result = test_true[i]\n",
    "    total = predict_result.shape[0] * predict_result.shape[1] \n",
    "    print(total)\n",
    "    sse = np.sum((true_result - predict_result) ** 2)\n",
    "    print(sse)\n",
    "    rmse_temp = np.sqrt(sse / total)\n",
    "    '''\n",
    "    if i == 0:\n",
    "        print(total)\n",
    "        print(sse)\n",
    "        print(rmse_temp)\n",
    "    '''\n",
    "    #print( np.sum(rmse_temp) / len(rmse_temp))\n",
    "    rmse.append(rmse_temp)\n",
    "\n",
    "    predict_result_f = predict_result.flatten()\n",
    "    true_result_f = true_result.flatten()\n",
    "    corr_temp = np.corrcoef(predict_result_f, true_result_f)[0, -1]\n",
    "    corr.append(corr_temp)\n",
    "RMSE = np.sum(rmse) / len(rmse)\n",
    "CORR = np.sum(corr) / len(corr)"
   ],
   "id": "b8acc57906ea2c57",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1456\n",
      "81305800.0\n",
      "1456\n",
      "81231420.0\n",
      "1456\n",
      "81360540.0\n",
      "1456\n",
      "81622720.0\n",
      "1456\n",
      "81751070.0\n",
      "1456\n",
      "81699630.0\n",
      "1456\n",
      "81830930.0\n",
      "1456\n",
      "81813310.0\n",
      "1456\n",
      "81844420.0\n",
      "1456\n",
      "82009224.0\n",
      "1456\n",
      "81972820.0\n",
      "1456\n",
      "82286880.0\n"
     ]
    }
   ],
   "execution_count": 130
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:25:31.834822Z",
     "start_time": "2024-08-14T05:25:31.821817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(RMSE)\n",
    "print(CORR)"
   ],
   "id": "1f9ff3c5b5c8ca6d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236.92038632660206\n",
      "0.9998858011077351\n"
     ]
    }
   ],
   "execution_count": 131
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T05:26:23.690093Z",
     "start_time": "2024-08-14T05:26:23.654046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "def loss(data_mask, depth, test_pred, test_true):\n",
    "    test_preds = np.array(test_pred, copy=True)\n",
    "    test_trues = np.array(test_true, copy=True)\n",
    "\n",
    "\n",
    "    test_preds = np.squeeze(test_preds)\n",
    "    test_trues = np.squeeze(test_trues)\n",
    "\n",
    "    test_preds[np.isnan(test_preds)] = 0\n",
    "    test_trues[np.isnan(test_trues)] = 0\n",
    "    mask = data_mask\n",
    "    print(mask.shape,test_preds.shape, test_trues.shape)\n",
    "    #     mask = np.squeeze(mask)\n",
    "    mask = mask[0]\n",
    "    mask=np.transpose(mask)\n",
    "\n",
    "    total = mask.shape[0] * mask.shape[1]\n",
    "    total_nan = len(mask[np.isnan(mask)])\n",
    "    total_real = total - total_nan\n",
    "    #     print('Total NaN:',total_nan)#统计数据中的nan值\n",
    "    #     print('Total Real:',total_real)#统计数据中的nan值\n",
    "    #     #nan：0 values ：1\n",
    "    mask[~np.isnan(mask)] = 1\n",
    "    mask[np.isnan(mask)] = 0\n",
    "    rmse = []\n",
    "    rmse_temp = []\n",
    "    nrmse = []\n",
    "    nrmse_temp = []\n",
    "    mae = []\n",
    "    mae_temp = []\n",
    "    for i in range(0, test_preds.shape[0]):\n",
    "        final_temp = mask * test_preds[i]\n",
    "        test_temp = mask * test_trues[i]\n",
    "        # np.sum((y_actual - y_predicted) ** 2)\n",
    "        sse = np.sum((test_temp - final_temp) ** 2)\n",
    "        mse_temp = sse / total_real\n",
    "        rmse_temp = np.sqrt(mse_temp)\n",
    "        nrmse_temp = rmse_temp / np.mean(test_temp)\n",
    "        rmse.append(rmse_temp)\n",
    "        nrmse.append(nrmse_temp)\n",
    "        mae_temp = mean_absolute_error(test_temp, final_temp) * total / total_real\n",
    "\n",
    "        mae.append(mae_temp)\n",
    "    #     print('NAN:',len(test_pred[np.isnan(test_pred)]))\n",
    "    #     print('TEST NANMIN',np.nanmin(test_pred))\n",
    "    #     print('TEST MIN',test_pred.min())\n",
    "    # print(str(depth)+'层')\n",
    "    RMSE = np.sum(rmse) / len(rmse)\n",
    "    MAE = np.sum(mae) / len(mae)\n",
    "    NRMSE = np.sum(nrmse) / len(nrmse)\n",
    "    # NRMSE = nrmse\n",
    "    print(str(depth) + '层:' + 'NRMSE RESULT:\\n', NRMSE)\n",
    "\n",
    "    #     print('MAE RESULT:\\n',MAE)\n",
    "\n",
    "    return NRMSE\n",
    "nrmse = loss(data_mask_t, 1, test_pred, test_true)"
   ],
   "id": "6d954248973cb687",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 28, 52) (12, 52, 28) (12, 52, 28)\n",
      "1层:NRMSE RESULT:\n",
      " -0.4619454622259082\n"
     ]
    }
   ],
   "execution_count": 133
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fda47df0bea059fe",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

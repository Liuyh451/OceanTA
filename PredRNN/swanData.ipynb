{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-22T08:59:02.035818Z",
     "start_time": "2025-03-22T08:59:02.022814Z"
    }
   },
   "source": "file_path=\"E:\\Dataset\\met_waves\\Swan_cropped\\swanSula201701_cropped.nc\"",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T14:18:48.380428Z",
     "start_time": "2025-03-10T14:18:48.354495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import netCDF4 as nc\n",
    "\n",
    "def read_nc_info(file_path):\n",
    "    # æ‰“å¼€ nc æ–‡ä»¶\n",
    "    dataset = nc.Dataset(file_path, 'r')\n",
    "\n",
    "    # è·å–æ‰€æœ‰å…¨å±€å±æ€§\n",
    "    global_attrs = {attr: dataset.getncattr(attr) for attr in dataset.ncattrs()}\n",
    "    \n",
    "    # è·å–æ‰€æœ‰å˜é‡\n",
    "    variables = list(dataset.variables.keys())\n",
    "\n",
    "    # è·å–ç»çº¬åº¦\n",
    "    lat = dataset.variables.get('latitude') or dataset.variables.get('lat')\n",
    "    lon = dataset.variables.get('longitude') or dataset.variables.get('lon')\n",
    "    time = dataset.variables.get('time')\n",
    "\n",
    "    # è¯»å–æ—¶é—´æ•°æ®\n",
    "    time_values = time[:].data if time is not None else None\n",
    "    time_step = None\n",
    "    if time_values is not None and len(time_values) > 1:\n",
    "        time_step = time_values[1] - time_values[0]  # è®¡ç®—æ—¶é—´é—´éš”\n",
    "\n",
    "    # è·å–æ¯ä¸ªå˜é‡çš„å•ä½ã€å½¢çŠ¶\n",
    "    variable_info = {}\n",
    "    for var_name in variables:\n",
    "        var = dataset.variables[var_name]\n",
    "        variable_info[var_name] = {\n",
    "            \"shape\": var.shape,\n",
    "            \"units\": var.units if \"units\" in var.ncattrs() else \"N/A\",\n",
    "            \"long_name\": var.long_name if \"long_name\" in var.ncattrs() else var_name\n",
    "        }\n",
    "\n",
    "    # æ‰“å°ä¿¡æ¯\n",
    "    print(\"ğŸŒ æ–‡ä»¶å…¨å±€å±æ€§:\")\n",
    "    for key, value in global_attrs.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "    print(\"\\nğŸ“ ç»çº¬åº¦ä¿¡æ¯:\")\n",
    "    print(f\"  çº¬åº¦èŒƒå›´: {lat[:].min()} ~ {lat[:].max()}\" if lat is not None else \"  æœªæ‰¾åˆ°çº¬åº¦æ•°æ®\")\n",
    "    print(f\"  ç»åº¦èŒƒå›´: {lon[:].min()} ~ {lon[:].max()}\" if lon is not None else \"  æœªæ‰¾åˆ°ç»åº¦æ•°æ®\")\n",
    "\n",
    "    print(\"\\nâ³ æ—¶é—´ä¿¡æ¯:\")\n",
    "    print(f\"  å…±æœ‰ {len(time_values)} ä¸ªæ—¶é—´æ­¥\")\n",
    "    print(f\"  é‡‡æ ·æ—¶é—´æ­¥é•¿: {time_step}\" if time_step is not None else \"  æœªæ‰¾åˆ°æ—¶é—´æ•°æ®æˆ–æ— æ³•è®¡ç®—æ­¥é•¿\")\n",
    "\n",
    "    print(\"\\nğŸŒŠ å˜é‡ä¿¡æ¯:\")\n",
    "    for var_name, info in variable_info.items():\n",
    "        print(f\"  {var_name}: {info['long_name']} (å•ä½: {info['units']}, å½¢çŠ¶: {info['shape']})\")\n",
    "\n",
    "    # å…³é—­æ–‡ä»¶\n",
    "    dataset.close()\n",
    "\n",
    "read_nc_info(file_path)\n"
   ],
   "id": "58d7f416daadfdcc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ æ–‡ä»¶å…¨å±€å±æ€§:\n",
      "  Conventions: CF-1.5\n",
      "  History: Thu Sep 30 11:31:36 2021: ncks -4 /lustre/storeB/project/fou/om/SWAN/Sula/INNER/Ut/swani_20170101.nc /lustre/storeB/project/SVV/E39/model/SWAN250/Sula/swanSula201701.nc\n",
      "Created with agioncmd version 1.4\n",
      "  Directional_convention: nautical\n",
      "  project: Sula i\n",
      "  run: T24\n",
      "  NCO: 4.7.2\n",
      "  institution: Norwegian Meteorological Institute, MET Norway\n",
      "  title: Spectral wave simulations in Norwegian fjords\n",
      "  summary: Hindcast simulations with the wave model SWAN (https://www.tudelft.nl/en/ceg/about-faculty/departments/hydraulic-engineering/sections/environmental-fluid-mechanics/research/swan) nested into the wave model WAM (hindcast data set NORA10, Reistad et al., 2011). Winds from WRF at 500m grid resolution are provided by Kjeller Vindteknikk/Norconsult. The grid spacing is 250m.\n",
      "  acknowledgement: The simulations are performed under collaboration with the Norwegian Public Roads Administration connected to the Coastal Highway E39-project in mid-Norway.\n",
      "  license: https://www.met.no/en/free-meteorological-data/Licensing-and-crediting\n",
      "  geospatial_lat_min: 62.0\n",
      "  geospatial_lat_max: 62.6\n",
      "  geospatial_lon_min: 5.3\n",
      "  geospatial_lon_max: 6.8\n",
      "  references: Furevik, B. R. and O. J. Aarnes (2021) Wave conditions in Sulafjorden,\n",
      "Vartdalsfjorden, Halsafjorden and Julsundet, MET Report no. 3/2021, https://www.met.no/publikasjoner/met-report/_/attachment/download/424fe337-b444-4801-913d-ba7207a29024:801be70d4b238debdf6abbfb897273e89304b6ae/MET-report_03-2021.pdf \n",
      "\n",
      "ğŸ“ ç»çº¬åº¦ä¿¡æ¯:\n",
      "  çº¬åº¦èŒƒå›´: 62.2 ~ 62.5\n",
      "  ç»åº¦èŒƒå›´: 5.6 ~ 6.2\n",
      "\n",
      "â³ æ—¶é—´ä¿¡æ¯:\n",
      "  å…±æœ‰ 744 ä¸ªæ—¶é—´æ­¥\n",
      "  é‡‡æ ·æ—¶é—´æ­¥é•¿: 3600\n",
      "\n",
      "ğŸŒŠ å˜é‡ä¿¡æ¯:\n",
      "  hs: hs (å•ä½: m, å½¢çŠ¶: (744, 128, 128))\n",
      "  tm02: tm02 (å•ä½: s, å½¢çŠ¶: (744, 128, 128))\n",
      "  theta0: theta0 (å•ä½: degrees, å½¢çŠ¶: (744, 128, 128))\n",
      "  time: time (å•ä½: seconds since 1970-01-01, å½¢çŠ¶: (744,))\n",
      "  longitude: longitude (å•ä½: degrees_east, å½¢çŠ¶: (128,))\n",
      "  latitude: latitude (å•ä½: degrees_north, å½¢çŠ¶: (128,))\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T14:21:41.340486Z",
     "start_time": "2025-03-10T14:21:41.324646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import netCDF4 as nc\n",
    "\n",
    "def list_nc_variables(file_path):\n",
    "    # æ‰“å¼€ nc æ–‡ä»¶\n",
    "    dataset = nc.Dataset(file_path, 'r')\n",
    "\n",
    "    # è·å–æ‰€æœ‰å˜é‡\n",
    "    variables = list(dataset.variables.keys())\n",
    "\n",
    "    # è¾“å‡ºå˜é‡ä¿¡æ¯\n",
    "    print(\"ğŸ“Œ æ–‡ä»¶ä¸­çš„æ‰€æœ‰å˜é‡ï¼š\")\n",
    "    for var_name in variables:\n",
    "        var = dataset.variables[var_name]\n",
    "        print(f\"  - {var_name} (å½¢çŠ¶: {var.shape}, ç»´åº¦: {var.dimensions})\")\n",
    "\n",
    "    dataset.close()\n",
    "\n",
    "# ç¤ºä¾‹ä½¿ç”¨\n",
    "list_nc_variables(file_path)\n"
   ],
   "id": "2b7587a747f54dcf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ æ–‡ä»¶ä¸­çš„æ‰€æœ‰å˜é‡ï¼š\n",
      "  - hs (å½¢çŠ¶: (744, 128, 128), ç»´åº¦: ('time', 'latitude', 'longitude'))\n",
      "  - tm02 (å½¢çŠ¶: (744, 128, 128), ç»´åº¦: ('time', 'latitude', 'longitude'))\n",
      "  - theta0 (å½¢çŠ¶: (744, 128, 128), ç»´åº¦: ('time', 'latitude', 'longitude'))\n",
      "  - time (å½¢çŠ¶: (744,), ç»´åº¦: ('time',))\n",
      "  - longitude (å½¢çŠ¶: (128,), ç»´åº¦: ('longitude',))\n",
      "  - latitude (å½¢çŠ¶: (128,), ç»´åº¦: ('latitude',))\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T08:59:07.022785Z",
     "start_time": "2025-03-22T08:59:05.461043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "# æå–æ•°æ®\n",
    "import xarray as xr\n",
    "ds = xr.open_dataset(file_path)\n",
    "hs = ds['hs'].values  # (744, 128, 128)\n",
    "tm02 = ds['tm02'].values  # (744, 128, 128)\n",
    "theta0 = ds['theta0'].values  # (744, 128, 128)\n",
    "\n",
    "# åˆå¹¶ä¸º 3 é€šé“\n",
    "data = np.stack([hs, tm02, theta0], axis=-1)  # å½¢çŠ¶ (744, 128, 128, 3)\n",
    "\n",
    "print(\"æ•°æ®å½¢çŠ¶:\", data.shape)  # è¾“å‡º (T, W, H, C)"
   ],
   "id": "d49d6b0e23940235",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ•°æ®å½¢çŠ¶: (744, 128, 128, 3)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T10:15:26.708277Z",
     "start_time": "2025-03-22T10:15:25.035040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# è¯»å–æ•°æ®\n",
    "dataset = xr.open_dataset(file_path)\n",
    "\n",
    "# æå–å˜é‡\n",
    "time = dataset['time'].values  # (744,)\n",
    "hs = dataset['hs'].values  # (744, 128, 128)\n",
    "tm02 = dataset['tm02'].values  # (744, 128, 128)\n",
    "theta0 = dataset['theta0'].values  # (744, 128, 128)\n",
    "\n",
    "# åˆ’åˆ†è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "\n",
    "num_samples = hs.shape[0]\n",
    "train_end = int(num_samples * train_ratio)\n",
    "val_end = int(num_samples * (train_ratio + val_ratio))\n",
    "\n",
    "train_data = {\n",
    "    'hs': hs[:train_end],\n",
    "    'tm02': tm02[:train_end],\n",
    "    'theta0': theta0[:train_end]\n",
    "}\n",
    "val_data = {\n",
    "    'hs': hs[train_end:val_end],\n",
    "    'tm02': tm02[train_end:val_end],\n",
    "    'theta0': theta0[train_end:val_end]\n",
    "}\n",
    "test_data = {\n",
    "    'hs': hs[val_end:],\n",
    "    'tm02': tm02[val_end:],\n",
    "    'theta0': theta0[val_end:]\n",
    "}\n",
    "\n",
    "# ä¿å­˜æ•°æ®\n",
    "output_dir = \"E:/Dataset/met_waves/Swan4predRNN\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "np.save(os.path.join(output_dir, \"train.npy\"), train_data)\n",
    "np.save(os.path.join(output_dir, \"val.npy\"), val_data)\n",
    "np.save(os.path.join(output_dir, \"test.npy\"), test_data)\n",
    "\n",
    "dataset.close()\n",
    "print(\"æ•°æ®å·²æˆåŠŸåˆ’åˆ†å¹¶ä¿å­˜ï¼\")\n"
   ],
   "id": "24dfc3dea2b6e1f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ•°æ®å·²æˆåŠŸåˆ’åˆ†å¹¶ä¿å­˜ï¼\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T09:03:49.731977Z",
     "start_time": "2025-03-27T09:03:48.982420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def check_nan_in_data(data):\n",
    "    if np.isnan(data).any():\n",
    "        print(\"âš ï¸ æ•°æ®ä¸­å­˜åœ¨ NaNï¼\")\n",
    "        exit()\n",
    "# å‡è®¾ `input_data` æ˜¯ä½ çš„è¾“å…¥æ•°æ®\n",
    "input_data = np.load(\"E:/Dataset/met_waves/Swan4predRNN/train.npy\",allow_pickle=True).item()\n",
    "check_nan_in_data(input_data)\n"
   ],
   "id": "79769502d919e77f",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 9\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# å‡è®¾ `input_data` æ˜¯ä½ çš„è¾“å…¥æ•°æ®\u001B[39;00m\n\u001B[0;32m      8\u001B[0m input_data \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mE:/Dataset/met_waves/Swan4predRNN/train.npy\u001B[39m\u001B[38;5;124m\"\u001B[39m,allow_pickle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m----> 9\u001B[0m \u001B[43mcheck_nan_in_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_data\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[2], line 4\u001B[0m, in \u001B[0;36mcheck_nan_in_data\u001B[1;34m(data)\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcheck_nan_in_data\u001B[39m(data):\n\u001B[1;32m----> 4\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43misnan\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39many():\n\u001B[0;32m      5\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mâš ï¸ æ•°æ®ä¸­å­˜åœ¨ NaNï¼\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      6\u001B[0m         exit()\n",
      "\u001B[1;31mTypeError\u001B[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# é…ç½®è·¯å¾„\n",
    "base_dir = \"E:/Dataset/met_waves/Swan_cropped\"\n",
    "output_dir = \"E:/Dataset/met_waves/Swan4predRNN/Large\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ç”Ÿæˆ12ä¸ªæœˆçš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆæŒ‰æ—¶é—´é¡ºåºï¼‰\n",
    "file_paths = [\n",
    "    os.path.join(base_dir, f\"swanSula2017{month:02d}_cropped.nc\")\n",
    "    for month in range(1, 13)  # ç”Ÿæˆ1-12æœˆ\n",
    "]\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# æ ¸å¿ƒæ•°æ®åˆ’åˆ†é€»è¾‘\n",
    "# ----------------------------------------------------\n",
    "def process_and_save_data(file_list, save_name):\n",
    "    \"\"\"è¯»å–å¤šä¸ªæ–‡ä»¶å¹¶åˆå¹¶æ•°æ®\"\"\"\n",
    "    merged_data = {\n",
    "        'hs': [],\n",
    "        'tm02': [],\n",
    "        'theta0': []\n",
    "    }\n",
    "\n",
    "    for file in file_list:\n",
    "        with xr.open_dataset(file) as ds:\n",
    "            # æå–å˜é‡æ•°æ®ï¼ˆå‡è®¾ç»´åº¦ä¸º [time, lat, lon]ï¼‰\n",
    "            merged_data['hs'].append(ds['hs'].values)\n",
    "            merged_data['tm02'].append(ds['tm02'].values)\n",
    "            merged_data['theta0'].append(ds['theta0'].values)\n",
    "\n",
    "    # æ²¿æ—¶é—´ç»´åº¦åˆå¹¶\n",
    "    final_data = {\n",
    "        key: np.concatenate(values, axis=0)\n",
    "        for key, values in merged_data.items()\n",
    "    }\n",
    "\n",
    "    # ä¿å­˜ä¸º.npyæ–‡ä»¶\n",
    "    np.save(os.path.join(output_dir, save_name), final_data)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# æ‰§è¡Œæ•°æ®åˆ’åˆ†\n",
    "# ----------------------------------------------------\n",
    "# å‰8ä¸ªæœˆï¼ˆ1-8æœˆï¼‰ä½œä¸ºè®­ç»ƒé›†\n",
    "process_and_save_data(file_paths[:8], \"train.npy\")\n",
    "\n",
    "# 9-10æœˆä½œä¸ºéªŒè¯é›†\n",
    "process_and_save_data(file_paths[8:10], \"val.npy\")\n",
    "\n",
    "# 11-12æœˆä½œä¸ºæµ‹è¯•é›†\n",
    "process_and_save_data(file_paths[10:], \"test.npy\")\n",
    "\n",
    "print(\"æ•°æ®åˆ’åˆ†å®Œæˆï¼\")\n",
    "print(f\"è®­ç»ƒé›†ï¼š{len(file_paths[:8])}ä¸ªæœˆ | éªŒè¯é›†ï¼š{len(file_paths[8:10])}ä¸ªæœˆ | æµ‹è¯•é›†ï¼š{len(file_paths[10:])}ä¸ªæœˆ\")"
   ],
   "id": "cd5d4f7dbfed3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7398a3e1adc91384"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

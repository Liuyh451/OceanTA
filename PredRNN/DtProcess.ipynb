{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T12:02:09.730562Z",
     "start_time": "2025-03-22T12:02:09.688562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import argparse\n",
    "\n",
    "# 创建命令行参数解析器\n",
    "parser = argparse.ArgumentParser(description='PyTorch video prediction model - PredRNN')\n",
    "\n",
    "# 添加训练/测试相关的参数\n",
    "parser.add_argument('--is_training', type=int, default=1)\n",
    "parser.add_argument('--device', type=str, default='cuda')\n",
    "\n",
    "# 添加数据集相关的参数\n",
    "parser.add_argument('--dataset_name', type=str, default='swan')\n",
    "parser.add_argument('--train_data_paths', type=str, default='E:/Dataset/met_waves/Swan4predRNN/train.npy')\n",
    "parser.add_argument('--valid_data_paths', type=str, default='E:/Dataset/met_waves/Swan4predRNN/val.npy')\n",
    "parser.add_argument('--save_dir', type=str, default='checkpoints/swan_predrnn_v2')\n",
    "parser.add_argument('--gen_frm_dir', type=str, default='results/swan_predrnn_v2')\n",
    "parser.add_argument('--input_length', type=int, default=10)\n",
    "parser.add_argument('--total_length', type=int, default=20)\n",
    "parser.add_argument('--img_width', type=int, default=64)\n",
    "parser.add_argument('--img_channel', type=int, default=1)\n",
    "\n",
    "# 添加模型相关的参数\n",
    "parser.add_argument('--model_name', type=str, default='predrnn_v2')\n",
    "parser.add_argument('--pretrained_model', type=str, default='')\n",
    "parser.add_argument('--num_hidden', type=str, default='128,128,128,128')\n",
    "parser.add_argument('--filter_size', type=int, default=5)\n",
    "parser.add_argument('--stride', type=int, default=1)\n",
    "parser.add_argument('--patch_size', type=int, default=4)\n",
    "parser.add_argument('--layer_norm', type=int, default=0)\n",
    "parser.add_argument('--decouple_beta', type=float, default=0.1)\n",
    "\n",
    "# 添加逆向调度采样相关的参数\n",
    "parser.add_argument('--reverse_scheduled_sampling', type=int, default=1)\n",
    "parser.add_argument('--r_sampling_step_1', type=float, default=25000)\n",
    "parser.add_argument('--r_sampling_step_2', type=int, default=50000)\n",
    "parser.add_argument('--r_exp_alpha', type=int, default=2500)\n",
    "# 添加调度采样相关的参数\n",
    "parser.add_argument('--scheduled_sampling', type=int, default=1)\n",
    "parser.add_argument('--sampling_stop_iter', type=int, default=50000)\n",
    "parser.add_argument('--sampling_start_value', type=float, default=1.0)\n",
    "parser.add_argument('--sampling_changing_rate', type=float, default=0.00002)\n",
    "\n",
    "# 添加优化相关的参数\n",
    "parser.add_argument('--lr', type=float, default=0.0001)\n",
    "parser.add_argument('--reverse_input', type=int, default=1)\n",
    "parser.add_argument('--batch_size', type=int, default=8)\n",
    "parser.add_argument('--max_iterations', type=int, default=80000)\n",
    "parser.add_argument('--display_interval', type=int, default=100)\n",
    "parser.add_argument('--test_interval', type=int, default=5000)\n",
    "parser.add_argument('--snapshot_interval', type=int, default=5000)\n",
    "parser.add_argument('--num_save_samples', type=int, default=10)\n",
    "parser.add_argument('--n_gpu', type=int, default=1)\n",
    "\n",
    "# 添加可视化相关的参数\n",
    "parser.add_argument('--visual', type=int, default=0)\n",
    "parser.add_argument('--visual_path', type=str, default='./decoupling_visual')\n",
    "\n",
    "# 添加基于动作的PredRNN相关的参数\n",
    "parser.add_argument('--injection_action', type=str, default='concat')\n",
    "parser.add_argument('--conv_on_input', type=int, default=0, help='conv on input')\n",
    "parser.add_argument('--res_on_conv', type=int, default=0, help='res on conv')\n",
    "parser.add_argument('--num_action_ch', type=int, default=4, help='num action ch')\n",
    "# 解析命令行参数\n",
    "args, unknown = parser.parse_known_args()\n",
    "# 打印解析后的参数\n",
    "print(args)"
   ],
   "id": "a04d90c221c4d102",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=8, conv_on_input=0, dataset_name='swan', decouple_beta=0.1, device='cuda', display_interval=100, filter_size=5, gen_frm_dir='results/swan_predrnn_v2', img_channel=1, img_width=64, injection_action='concat', input_length=10, is_training=1, layer_norm=0, lr=0.0001, max_iterations=80000, model_name='predrnn_v2', n_gpu=1, num_action_ch=4, num_hidden='128,128,128,128', num_save_samples=10, patch_size=4, pretrained_model='', r_exp_alpha=2500, r_sampling_step_1=25000, r_sampling_step_2=50000, res_on_conv=0, reverse_input=1, reverse_scheduled_sampling=1, sampling_changing_rate=2e-05, sampling_start_value=1.0, sampling_stop_iter=50000, save_dir='checkpoints/swan_predrnn_v2', scheduled_sampling=1, snapshot_interval=5000, stride=1, test_interval=5000, total_length=20, train_data_paths='E:/Dataset/met_waves/Swan4predRNN/train.npy', valid_data_paths='E:/Dataset/met_waves/Swan4predRNN/val.npy', visual=0, visual_path='./decoupling_visual')\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T11:59:57.958438Z",
     "start_time": "2025-03-22T11:59:57.646999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def reserve_schedule_sampling_exp(itr):\n",
    "    \"\"\"\n",
    "    根据当前迭代次数计算逆向调度采样的概率，并生成相应的采样标志。\n",
    "\n",
    "    参数:\n",
    "    itr (int): 当前迭代次数\n",
    "\n",
    "    返回:\n",
    "    real_input_flag (np.ndarray): 采样标志数组\n",
    "    \"\"\"\n",
    "    # 根据当前迭代次数计算逆向调度采样的概率\n",
    "    #r_eta表示逆向调度采样的概率值\n",
    "    if itr < args.r_sampling_step_1:\n",
    "        r_eta = 0.5\n",
    "    elif itr < args.r_sampling_step_2:\n",
    "        r_eta = 1.0 - 0.5 * math.exp(-float(itr - args.r_sampling_step_1) / args.r_exp_alpha)\n",
    "    else:\n",
    "        r_eta = 1.0\n",
    "    #eta 表示正向调度采样的概率值\n",
    "    if itr < args.r_sampling_step_1:\n",
    "        eta = 0.5\n",
    "    elif itr < args.r_sampling_step_2:\n",
    "        eta = 0.5 - (0.5 / (args.r_sampling_step_2 - args.r_sampling_step_1)) * (itr - args.r_sampling_step_1)\n",
    "    else:\n",
    "        eta = 0.0\n",
    "\n",
    "    # 生成逆向调度采样的标志\n",
    "    r_random_flip = np.random.random_sample(\n",
    "        (args.batch_size, args.input_length - 1))#生成一个元素的值在 [0, 1) 之间的数组用于后续判断是否进行逆向调度采样。\n",
    "    \"\"\"\n",
    "    该行代码的功能是根据生成的随机数数组 `r_random_flip` 和逆向调度采样的概率值 `r_eta`，生成一个布尔数组 `r_true_token`。\n",
    "    具体来说，如果 `r_random_flip` 中的元素小于 `r_eta`，则对应的 `r_true_token` 元素为 `True`，否则为 `False`。\n",
    "    \"\"\"\n",
    "    r_true_token = (r_random_flip < r_eta)\n",
    "    #下面这段代码和上面的那个差不多，是正向调度算法\n",
    "    random_flip = np.random.random_sample(\n",
    "        (args.batch_size, args.total_length - args.input_length - 1))\n",
    "    true_token = (random_flip < eta)\n",
    "    #创建两个三维数组 ones 和 zeros，用于后续生成采样标志，这两个数组的形状由图像宽度、高度和通道数决定。\n",
    "    ones = np.ones((args.img_width // args.patch_size,\n",
    "                    args.img_width // args.patch_size,\n",
    "                    args.patch_size ** 2 * args.img_channel))\n",
    "    zeros = np.zeros((args.img_width // args.patch_size,\n",
    "                      args.img_width // args.patch_size,\n",
    "                      args.patch_size ** 2 * args.img_channel))\n",
    "\n",
    "    real_input_flag = []\n",
    "    for i in range(args.batch_size):\n",
    "        for j in range(args.total_length - 2):\n",
    "            if j < args.input_length - 1:\n",
    "                if r_true_token[i, j]:\n",
    "                    real_input_flag.append(ones)\n",
    "                else:\n",
    "                    real_input_flag.append(zeros)\n",
    "            else:\n",
    "                if true_token[i, j - (args.input_length - 1)]:\n",
    "                    real_input_flag.append(ones)\n",
    "                else:\n",
    "                    real_input_flag.append(zeros)\n",
    "\n",
    "    real_input_flag = np.array(real_input_flag)\n",
    "    real_input_flag = np.reshape(real_input_flag,\n",
    "                                 (args.batch_size,\n",
    "                                  args.total_length - 2,\n",
    "                                  args.img_width // args.patch_size,\n",
    "                                  args.img_width // args.patch_size,\n",
    "                                  args.patch_size ** 2 * args.img_channel))\n",
    "    return real_input_flag\n",
    "\n",
    "# 定义调度采样函数\n",
    "def schedule_sampling(eta, itr):\n",
    "    \"\"\"\n",
    "    根据当前迭代次数和给定的eta值计算调度采样的概率，并生成相应的采样标志。\n",
    "\n",
    "    参数:\n",
    "    eta (float): 当前的eta值\n",
    "    itr (int): 当前迭代次数\n",
    "\n",
    "    返回:\n",
    "    eta (float): 更新后的eta值\n",
    "    real_input_flag (np.ndarray): 采样标志数组\n",
    "    \"\"\"\n",
    "    zeros = np.zeros((args.batch_size,\n",
    "                      args.total_length - args.input_length - 1,\n",
    "                      args.img_width // args.patch_size,\n",
    "                      args.img_width // args.patch_size,\n",
    "                      args.patch_size ** 2 * args.img_channel))\n",
    "    if not args.scheduled_sampling:\n",
    "        return 0.0, zeros\n",
    "\n",
    "    if itr < args.sampling_stop_iter:\n",
    "        eta -= args.sampling_changing_rate\n",
    "    else:\n",
    "        eta = 0.0\n",
    "    random_flip = np.random.random_sample(\n",
    "        (args.batch_size, args.total_length - args.input_length - 1))\n",
    "    true_token = (random_flip < eta)\n",
    "    ones = np.ones((args.img_width // args.patch_size,\n",
    "                    args.img_width // args.patch_size,\n",
    "                    args.patch_size ** 2 * args.img_channel))\n",
    "    zeros = np.zeros((args.img_width // args.patch_size,\n",
    "                      args.img_width // args.patch_size,\n",
    "                      args.patch_size ** 2 * args.img_channel))\n",
    "    real_input_flag = []\n",
    "    for i in range(args.batch_size):\n",
    "        for j in range(args.total_length - args.input_length - 1):\n",
    "            if true_token[i, j]:\n",
    "                real_input_flag.append(ones)\n",
    "            else:\n",
    "                real_input_flag.append(zeros)\n",
    "    real_input_flag = np.array(real_input_flag)\n",
    "    real_input_flag = np.reshape(real_input_flag,\n",
    "                                 (args.batch_size,\n",
    "                                  args.total_length - args.input_length - 1,\n",
    "                                  args.img_width // args.patch_size,\n",
    "                                  args.img_width // args.patch_size,\n",
    "                                  args.patch_size ** 2 * args.img_channel))\n",
    "    return eta, real_input_flag\n"
   ],
   "id": "ae7ea5a0225798d8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T12:08:09.243022Z",
     "start_time": "2025-03-22T12:08:09.225021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from core.utils import preprocess\n",
    "from core.data_provider import datasets_factory\n",
    "\n",
    "def train_wrapper(model):\n",
    "    \"\"\"\n",
    "    包装训练过程，包括加载预训练模型、数据加载、训练和测试。\n",
    "    \n",
    "    参数:\n",
    "    model (Model): 训练模型实例\n",
    "    \"\"\"\n",
    "    if args.pretrained_model:\n",
    "        model.load(args.pretrained_model)\n",
    "    # 加载数据，args.injection_action：是否使用某种特定的数据增强或特性注入\n",
    "    train_input_handle, test_input_handle = datasets_factory.data_provider(\n",
    "        args.dataset_name, args.train_data_paths, args.valid_data_paths, args.batch_size, args.img_width,\n",
    "        seq_length=args.total_length, injection_action=args.injection_action, is_training=True)\n",
    "\n",
    "    eta = args.sampling_start_value\n",
    "    \n",
    "    for itr in range(1, args.max_iterations + 1):\n",
    "        # 检查数据是否用完\n",
    "        if train_input_handle.no_batch_left():\n",
    "            train_input_handle.begin(do_shuffle=True)  # 重新洗牌数据\n",
    "        \n",
    "        # 读取一个批次的训练数据\n",
    "        ims = train_input_handle.get_batch()\n",
    "        ims = preprocess.reshape_patch(ims, args.patch_size)\n",
    "        \n",
    "        # 采样策略（不影响数据本身）\n",
    "        if args.reverse_scheduled_sampling == 1:\n",
    "            real_input_flag = reserve_schedule_sampling_exp(itr)\n",
    "        else:\n",
    "            eta, real_input_flag = schedule_sampling(eta, itr)\n",
    "        \n",
    "        # 输出数据形状\n",
    "        print(f\"Iteration {itr}: ims shape = {ims.shape}\")\n",
    "        print(f\"Sample values (first 3 elements): {ims.flatten()[:3]}\")\n",
    "        \n",
    "        train_input_handle.next()  # 读取下一个批次\n"
   ],
   "id": "20497b8329c3dbd6",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-22T12:08:14.780037Z",
     "start_time": "2025-03-22T12:08:14.127173Z"
    }
   },
   "source": [
    "from core.models.model_factory import Model\n",
    "\n",
    "# 创建模型实例\n",
    "model = Model(args)\n",
    "train_wrapper(model)\n"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Object arrays cannot be loaded when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# 创建模型实例\u001B[39;00m\n\u001B[0;32m      4\u001B[0m model \u001B[38;5;241m=\u001B[39m Model(args)\n\u001B[1;32m----> 5\u001B[0m \u001B[43mtrain_wrapper\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[11], line 14\u001B[0m, in \u001B[0;36mtrain_wrapper\u001B[1;34m(model)\u001B[0m\n\u001B[0;32m     12\u001B[0m     model\u001B[38;5;241m.\u001B[39mload(args\u001B[38;5;241m.\u001B[39mpretrained_model)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# 加载数据，args.injection_action：是否使用某种特定的数据增强或特性注入\u001B[39;00m\n\u001B[1;32m---> 14\u001B[0m train_input_handle, test_input_handle \u001B[38;5;241m=\u001B[39m \u001B[43mdatasets_factory\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_provider\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_data_paths\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalid_data_paths\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimg_width\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mseq_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtotal_length\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minjection_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minjection_action\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_training\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m eta \u001B[38;5;241m=\u001B[39m args\u001B[38;5;241m.\u001B[39msampling_start_value\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m itr \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, args\u001B[38;5;241m.\u001B[39mmax_iterations \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;66;03m# 检查数据是否用完\u001B[39;00m\n",
      "File \u001B[1;32mD:\\WorkSpace\\PycharmWorkSpace\\OceanTA\\PredRNN\\core\\data_provider\\datasets_factory.py:43\u001B[0m, in \u001B[0;36mdata_provider\u001B[1;34m(dataset_name, train_data_paths, valid_data_paths, batch_size, img_width, seq_length, injection_action, is_training)\u001B[0m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dataset_name\u001B[38;5;241m==\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mswan\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m     35\u001B[0m     \u001B[38;5;66;03m# 准备测试数据参数\u001B[39;00m\n\u001B[0;32m     36\u001B[0m     test_input_param \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m     37\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpaths\u001B[39m\u001B[38;5;124m'\u001B[39m: valid_data_list,\n\u001B[0;32m     38\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mminibatch_size\u001B[39m\u001B[38;5;124m'\u001B[39m: batch_size,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     41\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mswan test iterator\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     42\u001B[0m     }\n\u001B[1;32m---> 43\u001B[0m     test_input_handle \u001B[38;5;241m=\u001B[39m \u001B[43mdatasets_map\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mswan\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mInputHandle\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_input_param\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     44\u001B[0m     test_input_handle\u001B[38;5;241m.\u001B[39mbegin(do_shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)  \u001B[38;5;66;03m# 不打乱顺序开始测试数据迭代\u001B[39;00m\n\u001B[0;32m     46\u001B[0m     \u001B[38;5;66;03m# 如果是训练模式，准备训练数据参数\u001B[39;00m\n",
      "File \u001B[1;32mD:\\WorkSpace\\PycharmWorkSpace\\OceanTA\\PredRNN\\core\\data_provider\\swan.py:31\u001B[0m, in \u001B[0;36mInputHandle.__init__\u001B[1;34m(self, input_param)\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_batch_indices \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m---> 31\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcreate_indices()\n",
      "File \u001B[1;32mD:\\WorkSpace\\PycharmWorkSpace\\OceanTA\\PredRNN\\core\\data_provider\\swan.py:39\u001B[0m, in \u001B[0;36mInputHandle.load\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;124;03m加载数据，并合并成 3 通道\u001B[39;00m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m# 读取 npy 或 netCDF 数据\u001B[39;00m\n\u001B[1;32m---> 39\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpaths\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# 这里假设是 .npy 文件\u001B[39;00m\n\u001B[0;32m     40\u001B[0m hs \u001B[38;5;241m=\u001B[39m dataset[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhs\u001B[39m\u001B[38;5;124m'\u001B[39m]  \u001B[38;5;66;03m# (T, W, H)\u001B[39;00m\n\u001B[0;32m     41\u001B[0m tm02 \u001B[38;5;241m=\u001B[39m dataset[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtm02\u001B[39m\u001B[38;5;124m'\u001B[39m]  \u001B[38;5;66;03m# (T, W, H)\u001B[39;00m\n",
      "File \u001B[1;32mD:\\CondaEnvs\\torchtmp\\lib\\site-packages\\numpy\\lib\\npyio.py:432\u001B[0m, in \u001B[0;36mload\u001B[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001B[0m\n\u001B[0;32m    429\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mformat\u001B[39m\u001B[38;5;241m.\u001B[39mopen_memmap(file, mode\u001B[38;5;241m=\u001B[39mmmap_mode,\n\u001B[0;32m    430\u001B[0m                                   max_header_size\u001B[38;5;241m=\u001B[39mmax_header_size)\n\u001B[0;32m    431\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 432\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mformat\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_pickle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_pickle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    433\u001B[0m \u001B[43m                                 \u001B[49m\u001B[43mpickle_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpickle_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    434\u001B[0m \u001B[43m                                 \u001B[49m\u001B[43mmax_header_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_header_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    435\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    436\u001B[0m     \u001B[38;5;66;03m# Try a pickle\u001B[39;00m\n\u001B[0;32m    437\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m allow_pickle:\n",
      "File \u001B[1;32mD:\\CondaEnvs\\torchtmp\\lib\\site-packages\\numpy\\lib\\format.py:787\u001B[0m, in \u001B[0;36mread_array\u001B[1;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001B[0m\n\u001B[0;32m    784\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype\u001B[38;5;241m.\u001B[39mhasobject:\n\u001B[0;32m    785\u001B[0m     \u001B[38;5;66;03m# The array contained Python objects. We need to unpickle the data.\u001B[39;00m\n\u001B[0;32m    786\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m allow_pickle:\n\u001B[1;32m--> 787\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mObject arrays cannot be loaded when \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    788\u001B[0m                          \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_pickle=False\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    789\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m pickle_kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    790\u001B[0m         pickle_kwargs \u001B[38;5;241m=\u001B[39m {}\n",
      "\u001B[1;31mValueError\u001B[0m: Object arrays cannot be loaded when allow_pickle=False"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7cbf499451ed8d7d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
